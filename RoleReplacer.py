# -*- coding: utf-8 -*-

import bpy
import bmesh
import random
import os
import time
from bpy.props import StringProperty, EnumProperty, BoolProperty

# ç‰©ä½“åˆ†ç±»å…³é”®è¯å®šä¹‰
GENDER_KEYWORDS = ['male', 'female']
BODY_PART_KEYWORDS = ['upper', 'lower', 'feet', 'mouth', 'top', 'bottom', 'hair', 'nose', 'eyes', 'eyebrow', 'head', 'pieces', 'mouse']
SET_KEYWORDS = ['sets']

def diagnose_object_parsing(obj_name):
    """è¯Šæ–­ç‰©ä½“åç§°è§£æè¿‡ç¨‹
    
    Args:
        obj_name: ç‰©ä½“åç§°
        
    Returns:
        dict: è§£æç»“æœå’Œè¯Šæ–­ä¿¡æ¯
    """
    print(f"\nğŸ” è¯Šæ–­ç‰©ä½“åç§°è§£æ: {obj_name}")
    
    import re
    
    # å»é™¤Blenderè‡ªåŠ¨æ·»åŠ çš„åºå·
    base_name = re.sub(r'\.\d{3}$', '', obj_name)
    print(f"  åŸºç¡€åç§°: {base_name}")
    
    name_parts = base_name.split('_')
    print(f"  åˆ†å‰²ç»“æœ: {name_parts}")
    
    result = {
        'gender': None,
        'parts': [],
        'is_set': False,
        'original_name': obj_name,
        'base_name': base_name
    }
    
    print(f"\n  å…³é”®è¯åŒ¹é…è¿‡ç¨‹:")
    for i, part in enumerate(name_parts):
        part_lower = part.lower()
        print(f"    [{i}] '{part}' -> '{part_lower}'")
        
        # æ£€æŸ¥æ€§åˆ«
        if part_lower in GENDER_KEYWORDS:
            result['gender'] = part_lower
            print(f"        âœ… æ€§åˆ«åŒ¹é…: {part_lower}")
        else:
            print(f"        âŒ æ€§åˆ«ä¸åŒ¹é…")
        
        # æ£€æŸ¥éƒ¨ä½
        if part_lower in BODY_PART_KEYWORDS:
            result['parts'].append(part_lower)
            print(f"        âœ… éƒ¨ä½åŒ¹é…: {part_lower}")
        else:
            print(f"        âŒ éƒ¨ä½ä¸åŒ¹é…")
        
        # æ£€æŸ¥å¥—è£…
        if part_lower in SET_KEYWORDS:
            result['is_set'] = True
            print(f"        âœ… å¥—è£…åŒ¹é…: {part_lower}")
        else:
            print(f"        âŒ å¥—è£…ä¸åŒ¹é…")
    
    print(f"\n  æœ€ç»ˆè§£æç»“æœ:")
    print(f"    æ€§åˆ«: {result['gender']}")
    print(f"    éƒ¨ä½: {result['parts']}")
    print(f"    å¥—è£…: {result['is_set']}")
    
    return result

def is_exact_part_match(source_parts, target_parts):
    """æ£€æŸ¥éƒ¨ä»¶æ˜¯å¦ç²¾ç¡®åŒ¹é…ï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
    
    Args:
        source_parts: æºéƒ¨ä»¶åˆ—è¡¨
        target_parts: ç›®æ ‡éƒ¨ä»¶åˆ—è¡¨
        
    Returns:
        bool: æ˜¯å¦ç²¾ç¡®åŒ¹é…
    """
    # è½¬æ¢ä¸ºå°å†™è¿›è¡Œæ¯”è¾ƒ
    source_set = set(part.lower() for part in source_parts)
    target_set = set(part.lower() for part in target_parts)
    
    # ä¸¥æ ¼åŒ¹é…ï¼šæºéƒ¨ä»¶å’Œç›®æ ‡éƒ¨ä»¶å¿…é¡»å®Œå…¨ç›¸åŒ
    return source_set == target_set and len(source_set) > 0

def find_matching_random_target(source_gender, source_parts, target_objects):
    """é€šç”¨çš„éšæœºæ›¿æ¢å‡½æ•°ï¼Œæ ¹æ®æ€§åˆ«å’Œéƒ¨ä»¶ç±»å‹æŸ¥æ‰¾åŒ¹é…çš„ç›®æ ‡
    
    Args:
        source_gender: æºç‰©ä½“æ€§åˆ«
        source_parts: æºç‰©ä½“éƒ¨ä»¶åˆ—è¡¨
        target_objects: ç›®æ ‡ç‰©ä½“åˆ—è¡¨
        
    Returns:
        dict or None: åŒ¹é…çš„ç›®æ ‡ç‰©ä½“ï¼Œå¦‚æœæ²¡æœ‰åŒ¹é…åˆ™è¿”å›None
    """
    matching_targets = []
    
    for target_obj in target_objects:
        target_parsed = parse_object_name(target_obj['name'])
        
        # æ£€æŸ¥æ€§åˆ«å’Œéƒ¨ä»¶æ˜¯å¦åŒ¹é…
        if (target_parsed['gender'] == source_gender and 
            is_exact_part_match(source_parts, target_parsed['parts'])):
            matching_targets.append(target_obj)
    
    if matching_targets:
        target_obj = random.choice(matching_targets)
        print(f"   ğŸ¯ ç²¾ç¡®åŒ¹é…éšæœºæ›¿æ¢: æ€§åˆ«={source_gender}, éƒ¨ä»¶={source_parts} -> {target_obj['name']}")
        return target_obj
    else:
        print(f"   â­ï¸ è·³è¿‡ï¼šæ— æ€§åˆ«={source_gender}å’Œéƒ¨ä»¶={source_parts}åŒ¹é…çš„ç›®æ ‡")
        return None

def test_set_grouping():
    """æµ‹è¯•å¥—è£…åˆ†ç»„åŠŸèƒ½"""
    test_objects = [
        "Mod_Female_Sets_Upper_ClothingStoreNPC_001_Red_Lod0.001",
        "Mod_Female_Sets_Lower_ClothingStoreNPC_001_Red_Lod0.003"
    ]
    
    print("ğŸ” æµ‹è¯•å¥—è£…åˆ†ç»„:")
    print("=" * 60)
    
    for obj_name in test_objects:
        parsed = parse_object_name(obj_name)
        print(f"\nç‰©ä½“: {obj_name}")
        print(f"  æ€§åˆ«: {parsed['gender']}")
        print(f"  éƒ¨ä½: {parsed['parts']}")
        print(f"  å¥—è£…: {parsed['is_set']}")
        
        # æ¨¡æ‹Ÿåˆ†ç»„é€»è¾‘
        name_parts = obj_name.split('_')
        set_parts = []
        
        for part in name_parts:
            part_lower = part.lower()
            if part_lower not in GENDER_KEYWORDS + BODY_PART_KEYWORDS + SET_KEYWORDS:
                set_parts.append(part)
        
        if set_parts:
            set_id = f"{parsed['gender']}_{'_'.join(set_parts)}"
            base_name = '_'.join(set_parts)
        else:
            set_id = f"{parsed['gender']}_sets"
            base_name = f"{parsed['gender']}_sets"
        
        print(f"  å¥—è£…ID: {set_id}")
        print(f"  åŸºç¡€åç§°: {base_name}")
    
    print("=" * 60)

def initialize_random_seed():
    """åˆå§‹åŒ–éšæœºæ•°ç§å­"""
    # ä½¿ç”¨å½“å‰æ—¶é—´æˆ³ä½œä¸ºç§å­ï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œéƒ½æœ‰ä¸åŒçš„éšæœºæ€§
    # æ·»åŠ æ›´å¤šéšæœºæ€§å› ç´ 
    import hashlib
    seed_data = f"{time.time()}_{random.random()}_{id(bpy.context)}"
    seed = int(hashlib.md5(seed_data.encode()).hexdigest()[:8], 16)
    random.seed(seed)
    print(f"éšæœºæ•°ç§å­å·²åˆå§‹åŒ–: {seed}")

def snapshot_object_state(obj):
    """æ‹æ‘„ç‰©ä½“çŠ¶æ€å¿«ç…§
    
    Args:
        obj: è¦æ‹æ‘„çš„ç‰©ä½“å¯¹è±¡
        
    Returns:
        dict: ç‰©ä½“çŠ¶æ€ä¿¡æ¯
    """
    if not obj or obj.name not in bpy.data.objects:
        return {'exists': False}
    
    try:
        collections = [c.name for c in obj.users_collection] if hasattr(obj, 'users_collection') else []
        data_name = obj.data.name if getattr(obj, 'data', None) else None
        data_users = getattr(obj.data, 'users', None) if getattr(obj, 'data', None) else None
        
        return {
            'exists': True,
            'name': obj.name,
            'visible_viewport': not obj.hide_viewport,
            'visible_render': not obj.hide_render,
            'in_collections': collections,
            'collection_count': len(collections),
            'data_name': data_name,
            'data_users': data_users,
            'type': obj.type if hasattr(obj, 'type') else None,
            'location': tuple(obj.location) if hasattr(obj, 'location') else None,
            'parent': obj.parent.name if obj.parent else None,
        }
    except Exception as e:
        return {'exists': False, 'error': str(e)}

def diff_states(before, after, obj_name):
    """å¯¹æ¯”ç‰©ä½“çŠ¶æ€å·®å¼‚
    
    Args:
        before: æ›¿æ¢å‰çŠ¶æ€
        after: æ›¿æ¢åçŠ¶æ€
        obj_name: ç‰©ä½“åç§°
        
    Returns:
        str: å·®å¼‚æè¿°
    """
    if not before.get('exists', False) and not after.get('exists', False):
        return f"[{obj_name}] å‰åéƒ½ä¸å­˜åœ¨"
    
    if before.get('exists', False) and not after.get('exists', False):
        return f"[{obj_name}] âŒ æ›¿æ¢åå¯¹è±¡ä¸å­˜åœ¨ï¼ˆç–‘ä¼¼è¢«åˆ é™¤ï¼‰"
    
    if not before.get('exists', False) and after.get('exists', False):
        return f"[{obj_name}] âœ… æ›¿æ¢åå¯¹è±¡é‡æ–°å‡ºç°"
    
    msgs = []
    
    # æ£€æŸ¥é›†åˆé“¾æ¥
    if before.get('collection_count', 0) > 0 and after.get('collection_count', 0) == 0:
        msgs.append("âŒ å¯¹è±¡æœªé“¾æ¥åˆ°ä»»ä½•é›†åˆï¼ˆOutlinerçœ‹ä¸åˆ°ï¼‰")
    
    # æ£€æŸ¥å¯è§æ€§
    if not after.get('visible_viewport', True):
        msgs.append("âš ï¸ å¯¹è±¡è§†å£éšè—")
    
    if not after.get('visible_render', True):
        msgs.append("âš ï¸ å¯¹è±¡æ¸²æŸ“éšè—")
    
    # æ£€æŸ¥ç½‘æ ¼æ•°æ®
    if before.get('data_name') and not after.get('data_name'):
        msgs.append("âŒ å¯¹è±¡ç½‘æ ¼æ•°æ®ä¸¢å¤±")
    
    if after.get('data_name') and after.get('data_users') == 0:
        msgs.append("âš ï¸ å¯¹è±¡ç½‘æ ¼æ•°æ®users==0ï¼ˆå¯èƒ½è¢«æ¸…ç†ï¼‰")
    
    # æ£€æŸ¥é›†åˆå˜æ›´
    if before.get('in_collections') != after.get('in_collections'):
        msgs.append(f"ğŸ“ é›†åˆå˜æ›´: {before.get('in_collections')} -> {after.get('in_collections')}")
    
    # æ£€æŸ¥ç½‘æ ¼å˜æ›´
    if before.get('data_name') != after.get('data_name'):
        msgs.append(f"ğŸ”§ ç½‘æ ¼å˜æ›´: {before.get('data_name')} -> {after.get('data_name')}")
    
    return f"[{obj_name}] " + ("ï¼›".join(msgs) if msgs else "âœ… çŠ¶æ€æ­£å¸¸")

def log_replacement_step(step_name, obj_name, details=""):
    """è®°å½•æ›¿æ¢æ­¥éª¤æ—¥å¿—
    
    Args:
        step_name: æ­¥éª¤åç§°
        obj_name: ç‰©ä½“åç§°
        details: è¯¦ç»†ä¿¡æ¯
    """
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨è¯Šæ–­
    scene = bpy.context.scene
    if not getattr(scene, 'enable_replacement_diagnostics', False):
        return
    
    timestamp = time.strftime("%H:%M:%S")
    print(f"[{timestamp}] ğŸ” {step_name} - {obj_name}: {details}")

def validate_imported_object(obj):
    """éªŒè¯å¯¼å…¥çš„ç‰©ä½“æ˜¯å¦æœ‰æ•ˆ
    
    Args:
        obj: è¦éªŒè¯çš„ç‰©ä½“
        
    Returns:
        tuple: (is_valid, error_message)
    """
    if not obj:
        return False, "ç‰©ä½“å¯¹è±¡ä¸ºç©º"
    
    if obj.name not in bpy.data.objects:
        return False, "ç‰©ä½“ä¸åœ¨bpy.data.objectsä¸­"
    
    if obj.type != 'MESH':
        return False, f"ç‰©ä½“ç±»å‹ä¸æ˜¯MESH: {obj.type}"
    
    if not obj.data:
        return False, "ç‰©ä½“æ²¡æœ‰ç½‘æ ¼æ•°æ®"
    
    if not hasattr(obj.data, 'vertices') or len(obj.data.vertices) == 0:
        return False, "ç½‘æ ¼æ•°æ®æ²¡æœ‰é¡¶ç‚¹"
    
    if not hasattr(obj.data, 'polygons') or len(obj.data.polygons) == 0:
        return False, "ç½‘æ ¼æ•°æ®æ²¡æœ‰é¢"
    
    return True, "éªŒè¯é€šè¿‡"

def log_imported_object_validation(obj_name, obj, prefix=""):
    """è®°å½•å¯¼å…¥ç‰©ä½“çš„éªŒè¯ä¿¡æ¯
    
    Args:
        obj_name: ç‰©ä½“åç§°
        obj: ç‰©ä½“å¯¹è±¡
        prefix: å‰ç¼€
    """
    is_valid, error_msg = validate_imported_object(obj)
    if is_valid:
        vertices_count = len(obj.data.vertices) if obj.data else 0
        polygons_count = len(obj.data.polygons) if obj.data else 0
        print(f"{prefix}[{obj_name}] âœ… éªŒè¯é€šè¿‡ - é¡¶ç‚¹:{vertices_count} é¢:{polygons_count}")
    else:
        print(f"{prefix}[{obj_name}] âŒ éªŒè¯å¤±è´¥ - {error_msg}")
    
    return is_valid

def validate_replacement_consistency(replacement_plan):
    """éªŒè¯æ›¿æ¢è®¡åˆ’çš„ä¸€è‡´æ€§ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰éƒ¨ä»¶ç±»å‹é”™è¯¯æ›¿æ¢
    
    Args:
        replacement_plan: æ›¿æ¢è®¡åˆ’åˆ—è¡¨
        
    Returns:
        dict: éªŒè¯ç»“æœç»Ÿè®¡
    """
    print(f"\nğŸ” éªŒè¯æ›¿æ¢è®¡åˆ’ä¸€è‡´æ€§...")
    
    # ç»Ÿè®¡éƒ¨ä»¶ç±»å‹
    source_parts_count = {}
    target_parts_count = {}
    part_mapping = {}
    
    for source_obj, target_obj in replacement_plan:
        source_info = parse_object_name(source_obj.name)
        target_info = target_obj['parsed_info']
        
        # ç»Ÿè®¡æºéƒ¨ä»¶
        for part in source_info['parts']:
            source_parts_count[part] = source_parts_count.get(part, 0) + 1
        
        # ç»Ÿè®¡ç›®æ ‡éƒ¨ä»¶
        for part in target_info['parts']:
            target_parts_count[part] = target_parts_count.get(part, 0) + 1
        
        # è®°å½•éƒ¨ä»¶æ˜ å°„
        for source_part in source_info['parts']:
            if source_part not in part_mapping:
                part_mapping[source_part] = []
            part_mapping[source_part].extend(target_info['parts'])
    
    print(f"\nğŸ“Š éƒ¨ä»¶ç±»å‹ç»Ÿè®¡:")
    print(f"  æºéƒ¨ä»¶: {source_parts_count}")
    print(f"  ç›®æ ‡éƒ¨ä»¶: {target_parts_count}")
    
    print(f"\nğŸ”— éƒ¨ä»¶æ˜ å°„å…³ç³»:")
    for source_part, target_parts in part_mapping.items():
        unique_targets = list(set(target_parts))
        print(f"  {source_part} -> {unique_targets}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯çš„æ˜ å°„
        if source_part not in unique_targets:
            print(f"    âš ï¸ è­¦å‘Š: {source_part} è¢«æ›¿æ¢ä¸ºå…¶ä»–ç±»å‹éƒ¨ä»¶")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰éƒ¨ä»¶ç±»å‹å†²çª
    conflicts = []
    for source_part, target_parts in part_mapping.items():
        if source_part not in target_parts:
            conflicts.append(f"{source_part} -> {list(set(target_parts))}")
    
    if conflicts:
        print(f"\nâŒ å‘ç°éƒ¨ä»¶ç±»å‹å†²çª:")
        for conflict in conflicts:
            print(f"  {conflict}")
    else:
        print(f"\nâœ… éƒ¨ä»¶ç±»å‹æ˜ å°„æ­£å¸¸")
    
    return {
        'source_parts': source_parts_count,
        'target_parts': target_parts_count,
        'part_mapping': part_mapping,
        'conflicts': conflicts
    }

def validate_replacement_results(replacement_plan):
    """éªŒè¯æ›¿æ¢ç»“æœï¼Œæ£€æŸ¥æ›¿æ¢åçš„ç‰©ä½“éƒ¨ä»¶ç±»å‹æ˜¯å¦æ­£ç¡®
    
    Args:
        replacement_plan: æ›¿æ¢è®¡åˆ’åˆ—è¡¨
        
    Returns:
        dict: éªŒè¯ç»“æœ
    """
    print(f"\nğŸ” éªŒè¯æ›¿æ¢ç»“æœ...")
    
    correct_replacements = 0
    incorrect_replacements = 0
    part_type_errors = []
    
    for source_obj, target_obj in replacement_plan:
        source_info = parse_object_name(source_obj.name)
        target_info = target_obj['parsed_info']
        
        # æ£€æŸ¥éƒ¨ä»¶ç±»å‹æ˜¯å¦åŒ¹é…
        source_parts = set(source_info['parts'])
        target_parts = set(target_info['parts'])
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å®Œå…¨åŒ¹é…çš„éƒ¨ä»¶
        exact_matches = source_parts.intersection(target_parts)
        
        if exact_matches:
            correct_replacements += 1
            print(f"  âœ… {source_obj.name} -> {target_obj['name']} (åŒ¹é…éƒ¨ä»¶: {list(exact_matches)})")
        else:
            incorrect_replacements += 1
            part_type_errors.append({
                'source': source_obj.name,
                'target': target_obj['name'],
                'source_parts': list(source_parts),
                'target_parts': list(target_parts)
            })
            print(f"  âŒ {source_obj.name} -> {target_obj['name']}")
            print(f"      æºéƒ¨ä»¶: {list(source_parts)}")
            print(f"      ç›®æ ‡éƒ¨ä»¶: {list(target_parts)}")
            print(f"      âš ï¸ éƒ¨ä»¶ç±»å‹ä¸åŒ¹é…ï¼Œå¯èƒ½å¯¼è‡´è§†è§‰ä¸Šçš„'æ¶ˆå¤±'")
    
    print(f"\nğŸ“Š æ›¿æ¢ç»“æœéªŒè¯:")
    print(f"  æ­£ç¡®æ›¿æ¢: {correct_replacements}")
    print(f"  é”™è¯¯æ›¿æ¢: {incorrect_replacements}")
    
    if part_type_errors:
        print(f"\nâŒ å‘ç°éƒ¨ä»¶ç±»å‹é”™è¯¯:")
        for error in part_type_errors:
            print(f"  {error['source']} ({error['source_parts']}) -> {error['target']} ({error['target_parts']})")
    
    return {
        'correct': correct_replacements,
        'incorrect': incorrect_replacements,
        'errors': part_type_errors
    }

def log_object_state(obj_name, state_snapshot, prefix=""):
    """è®°å½•ç‰©ä½“çŠ¶æ€æ—¥å¿—
    
    Args:
        obj_name: ç‰©ä½“åç§°
        state_snapshot: çŠ¶æ€å¿«ç…§
        prefix: å‰ç¼€
    """
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨è¯Šæ–­
    scene = bpy.context.scene
    if not getattr(scene, 'enable_replacement_diagnostics', False):
        return
    
    if not state_snapshot.get('exists', False):
        print(f"{prefix}[{obj_name}] âŒ å¯¹è±¡ä¸å­˜åœ¨")
        return
    
    collections = state_snapshot.get('in_collections', [])
    data_name = state_snapshot.get('data_name', 'None')
    data_users = state_snapshot.get('data_users', 'N/A')
    
    print(f"{prefix}[{obj_name}] é›†åˆ:{collections} ç½‘æ ¼:{data_name}(users:{data_users}) å¯è§:{state_snapshot.get('visible_viewport', False)}")

def weighted_random_choice(targets, used_targets=None):
    """å¸¦æƒé‡çš„éšæœºé€‰æ‹©ï¼Œé¿å…é‡å¤é€‰æ‹©
    
    Args:
        targets (list): ç›®æ ‡ç‰©ä½“åˆ—è¡¨æˆ–å…ƒç»„åˆ—è¡¨
        used_targets (set): å·²ä½¿ç”¨çš„ç›®æ ‡ç‰©ä½“åç§°é›†åˆ
        
    Returns:
        dict or tuple: é€‰æ‹©çš„ç›®æ ‡ç‰©ä½“
    """
    if not targets:
        return None
    
    if not used_targets:
        return random.choice(targets)
    
    # åˆ†ç¦»å·²ä½¿ç”¨å’Œæœªä½¿ç”¨çš„ç›®æ ‡
    unused_targets = []
    used_targets_list = []
    
    for target in targets:
        # å¤„ç†å…ƒç»„æ ¼å¼ (id, set_info) æˆ–å­—å…¸æ ¼å¼
        if isinstance(target, tuple):
            target_id = target[0]
        else:
            target_id = target['name']
            
        if target_id in used_targets:
            used_targets_list.append(target)
        else:
            unused_targets.append(target)
    
    # ä¼˜å…ˆé€‰æ‹©æœªä½¿ç”¨çš„ç›®æ ‡
    if unused_targets:
        return random.choice(unused_targets)
    elif used_targets_list:
        # å¦‚æœæ‰€æœ‰ç›®æ ‡éƒ½å·²ä½¿ç”¨ï¼Œéšæœºé€‰æ‹©ä¸€ä¸ª
        return random.choice(used_targets_list)
    else:
        return random.choice(targets)

def parse_object_name(obj_name):
    """è§£æç‰©ä½“åç§°ï¼Œæå–æ€§åˆ«ã€éƒ¨ä½å’Œå¥—è£…ä¿¡æ¯
    
    Args:
        obj_name (str): ç‰©ä½“åç§°
        
    Returns:
        dict: åŒ…å«è§£æç»“æœçš„å­—å…¸
            - gender: æ€§åˆ« ('male'/'female' æˆ– None)
            - parts: éƒ¨ä½åˆ—è¡¨
            - is_set: æ˜¯å¦ä¸ºå¥—è£…
            - original_name: åŸå§‹åç§°
            - base_name: å»é™¤åºå·çš„åŸºç¡€åç§°
    """
    import re
    
    # å»é™¤Blenderè‡ªåŠ¨æ·»åŠ çš„åºå·ï¼ˆå¦‚ .001, .002 ç­‰ï¼‰
    base_name = re.sub(r'\.\d{3}$', '', obj_name)
    
    name_parts = base_name.split('_')
    result = {
        'gender': None,
        'parts': [],
        'is_set': False,
        'original_name': obj_name,
        'base_name': base_name
    }
    
    for part in name_parts:
        part_lower = part.lower()
        
        # æ£€æŸ¥æ€§åˆ«
        if part_lower in GENDER_KEYWORDS:
            result['gender'] = part_lower
        
        # æ£€æŸ¥éƒ¨ä½
        if part_lower in BODY_PART_KEYWORDS:
            result['parts'].append(part_lower)
        
        # æ£€æŸ¥å¥—è£…
        if part_lower in SET_KEYWORDS:
            result['is_set'] = True
    
    return result

def create_hidden_import_collection():
    """åˆ›å»ºä¸å¯è§ä¸å¯æ¸²æŸ“çš„å›ºå®šé›†åˆæ¥å­˜å‚¨å¯¼å…¥çš„ç‰©ä½“
    
    Returns:
        bpy.types.Collection: éšè—çš„å¯¼å…¥é›†åˆ
    """
    collection_name = "Hidden_Imported_Objects"
    hidden_collection = bpy.data.collections.get(collection_name)
    
    if not hidden_collection:
        hidden_collection = bpy.data.collections.new(collection_name)
        bpy.context.scene.collection.children.link(hidden_collection)
        
        # è®¾ç½®ä¸ºä¸å¯è§å’Œä¸å¯æ¸²æŸ“
        hidden_collection.hide_viewport = True
        hidden_collection.hide_render = True
        
        print(f"åˆ›å»ºéšè—å¯¼å…¥é›†åˆ: {collection_name}")
    
    return hidden_collection

def create_collection_hierarchy():
    """åˆ›å»ºåˆ†ç±»é›†åˆçš„å±‚çº§ç»“æ„
    
    Returns:
        bpy.types.Collection: ä¸»åˆ†ç±»é›†åˆ
    """
    # åˆ›å»ºä¸»åˆ†ç±»é›†åˆ
    main_collection_name = "Object_Classification"
    main_collection = bpy.data.collections.get(main_collection_name)
    if not main_collection:
        main_collection = bpy.data.collections.new(main_collection_name)
        bpy.context.scene.collection.children.link(main_collection)
    
    # åˆ›å»ºæ€§åˆ«å­é›†åˆ
    gender_collections = {}
    for gender in GENDER_KEYWORDS:
        gender_name = gender.capitalize()
        gender_collection = bpy.data.collections.get(gender_name)
        if not gender_collection:
            gender_collection = bpy.data.collections.new(gender_name)
            main_collection.children.link(gender_collection)
        gender_collections[gender] = gender_collection
    
    # åˆ›å»ºéƒ¨ä½å­é›†åˆ
    for gender, gender_collection in gender_collections.items():
        for part in BODY_PART_KEYWORDS:
            part_collection_name = f"{gender_collection.name}_{part.capitalize()}"
            part_collection = bpy.data.collections.get(part_collection_name)
            if not part_collection:
                part_collection = bpy.data.collections.new(part_collection_name)
                gender_collection.children.link(part_collection)
    
    return main_collection

def classify_and_organize_objects():
    """åˆ†ç±»å¹¶ç»„ç»‡ç‰©ä½“åˆ°å¯¹åº”é›†åˆ
    
    Returns:
        str: åˆ†ç±»ç»“æœä¿¡æ¯
    """
    # åˆ›å»ºé›†åˆå±‚çº§ç»“æ„
    create_collection_hierarchy()
    
    # è·å–æ‰€æœ‰é€‰ä¸­çš„ç‰©ä½“
    selected_objects = bpy.context.selected_objects
    
    if not selected_objects:
        return "æ²¡æœ‰é€‰ä¸­ä»»ä½•ç‰©ä½“"
    
    classified_count = 0
    unclassified_count = 0
    mesh_objects = [obj for obj in selected_objects if obj.type == 'MESH']
    
    if not mesh_objects:
        return "é€‰ä¸­çš„ç‰©ä½“ä¸­æ²¡æœ‰ç½‘æ ¼ç‰©ä½“"
    
    for obj in mesh_objects:
        # è§£æç‰©ä½“åç§°
        parsed_info = parse_object_name(obj.name)
        
        # ç¡®å®šç›®æ ‡é›†åˆ
        target_collection = None
        
        if parsed_info['gender'] and parsed_info['parts']:
            # æ ¹æ®æ€§åˆ«å’Œéƒ¨ä½ç¡®å®šç›®æ ‡é›†åˆ
            gender_name = parsed_info['gender'].capitalize()
            part_name = parsed_info['parts'][0].capitalize()
            target_collection_name = f"{gender_name}_{part_name}"
            target_collection = bpy.data.collections.get(target_collection_name)
        
        # ç§»åŠ¨ç‰©ä½“åˆ°ç›®æ ‡é›†åˆ
        if target_collection:
            # ä»å½“å‰é›†åˆä¸­ç§»é™¤
            for collection in obj.users_collection:
                collection.objects.unlink(obj)
            
            # æ·»åŠ åˆ°ç›®æ ‡é›†åˆ
            target_collection.objects.link(obj)
            classified_count += 1
            print(f"ç‰©ä½“ '{obj.name}' å·²åˆ†ç±»åˆ°é›†åˆ '{target_collection.name}'")
        else:
            unclassified_count += 1
            missing_info = []
            if not parsed_info['gender']:
                missing_info.append("æ€§åˆ«")
            if not parsed_info['parts']:
                missing_info.append("éƒ¨ä½")
            print(f"ç‰©ä½“ '{obj.name}' æ— æ³•åˆ†ç±»ï¼Œç¼ºå°‘: {', '.join(missing_info)}")
    
    return f"åˆ†ç±»å®Œæˆï¼š{classified_count} ä¸ªç‰©ä½“å·²åˆ†ç±»ï¼Œ{unclassified_count} ä¸ªç‰©ä½“æ— æ³•åˆ†ç±»"

def check_object_exists_in_hidden_collection(obj_name):
    """æ£€æŸ¥ç‰©ä½“æ˜¯å¦å·²å­˜åœ¨äºéšè—é›†åˆä¸­
    
    Args:
        obj_name (str): ç‰©ä½“åç§°
        
    Returns:
        bpy.types.Object or None: å¦‚æœå­˜åœ¨è¿”å›ç‰©ä½“å¯¹è±¡ï¼Œå¦åˆ™è¿”å›None
    """
    hidden_collection = bpy.data.collections.get("Hidden_Imported_Objects")
    if not hidden_collection:
        return None
    
    # æ£€æŸ¥éšè—é›†åˆä¸­æ˜¯å¦å­˜åœ¨åŒåç‰©ä½“
    for obj in hidden_collection.objects:
        if obj.name == obj_name:
            return obj
    
    return None

def load_objects_from_blend(file_path):
    """ä».blendæ–‡ä»¶åŠ è½½ç‰©ä½“ä¿¡æ¯ï¼ˆæ”¹è¿›ç‰ˆæœ¬ - æ£€æŸ¥é‡å¤å¯¼å…¥ï¼‰
    
    Args:
        file_path (str): .blendæ–‡ä»¶è·¯å¾„
        
    Returns:
        list: åŒ…å«ç‰©ä½“ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨
    """
    # å¤„ç†æ–‡ä»¶è·¯å¾„
    file_path = bpy.path.abspath(file_path)
    print(f"å°è¯•åŠ è½½æ–‡ä»¶: {file_path}")
    
    if not os.path.exists(file_path):
        print(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return []
    
    objects_info = []
    
    try:
        # æ–°æ–¹æ³•ï¼šåªè¯»å–æ–‡ä»¶ä¿¡æ¯ï¼Œä¸å¯¼å…¥åˆ°åœºæ™¯
        print(f"æ­£åœ¨è¯»å–æ–‡ä»¶ä¿¡æ¯: {file_path}")
        
        # ä½¿ç”¨ bpy.data.libraries.load åªè¯»å–ä¿¡æ¯ï¼Œä¸å¯¼å…¥
        with bpy.data.libraries.load(file_path, link=False) as (data_from, data_to):
            # åªå¤„ç†ç½‘æ ¼ç‰©ä½“
            mesh_objects = [name for name in data_from.objects if name in data_from.meshes]
            print(f"æ‰¾åˆ° {len(mesh_objects)} ä¸ªç½‘æ ¼ç‰©ä½“")
            
            # ä¸ºæ¯ä¸ªç½‘æ ¼ç‰©ä½“åˆ›å»ºä¿¡æ¯ï¼Œæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            for obj_name in mesh_objects:
                try:
                    # æ£€æŸ¥ç‰©ä½“æ˜¯å¦å·²å­˜åœ¨äºéšè—é›†åˆä¸­
                    existing_obj = check_object_exists_in_hidden_collection(obj_name)
                    
                    # è§£æç‰©ä½“åç§°
                    parsed_info = parse_object_name(obj_name)
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ•ˆä¿¡æ¯
                    if parsed_info['gender'] and parsed_info['parts']:
                        # åˆ›å»ºç‰©ä½“ä¿¡æ¯
                        obj_info = {
                            'name': obj_name,
                            'object': existing_obj,  # å¦‚æœå·²å­˜åœ¨åˆ™ä½¿ç”¨ç°æœ‰ç‰©ä½“
                            'parsed_info': parsed_info,
                            'location': (0, 0, 0),  # é»˜è®¤ä½ç½®
                            'rotation': (0, 0, 0),  # é»˜è®¤æ—‹è½¬
                            'scale': (1, 1, 1),     # é»˜è®¤ç¼©æ”¾
                            'already_imported': existing_obj is not None  # æ ‡è®°æ˜¯å¦å·²å¯¼å…¥
                        }
                        
                        objects_info.append(obj_info)
                        
                        if existing_obj:
                            print(f"  âœ“ ç‰©ä½“ '{obj_name}' å·²å­˜åœ¨ï¼Œç›´æ¥å¼•ç”¨")
                        else:
                            print(f"  + ç‰©ä½“ '{obj_name}' éœ€è¦å¯¼å…¥")
                            
                except Exception as e:
                    print(f"å¤„ç†ç‰©ä½“ {obj_name} æ—¶å‡ºé”™: {e}")
                    continue
        
        print(f"æ–‡ä»¶è¯»å–å®Œæˆ: æ€»ç½‘æ ¼ç‰©ä½“ {len(mesh_objects)} ä¸ªï¼Œæœ‰æ•ˆç‰©ä½“ {len(objects_info)} ä¸ª")
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç¬¦åˆå‘½åè§„èŒƒçš„ç‰©ä½“ï¼Œä½†æœ‰ç½‘æ ¼ç‰©ä½“ï¼Œåˆ™æä¾›å¤‡ç”¨æ–¹æ¡ˆ
        if len(mesh_objects) > 0 and len(objects_info) == 0:
            print("è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆå‘½åè§„èŒƒçš„ç‰©ä½“ï¼Œå°è¯•åŠ è½½æ‰€æœ‰ç½‘æ ¼ç‰©ä½“...")
            
            # æä¾›å¤‡ç”¨åŠ è½½é€‰é¡¹ï¼šåŠ è½½æ‰€æœ‰ç½‘æ ¼ç‰©ä½“ï¼ˆä¸è¿›è¡Œå‘½åè¿‡æ»¤ï¼‰
            for obj_name in mesh_objects:
                try:
                    # æ£€æŸ¥ç‰©ä½“æ˜¯å¦å·²å­˜åœ¨äºéšè—é›†åˆä¸­
                    existing_obj = check_object_exists_in_hidden_collection(obj_name)
                    
                    # åˆ›å»ºåŸºæœ¬çš„è§£æä¿¡æ¯
                    basic_info = {
                        'gender': 'unknown',
                        'parts': ['unknown'],
                        'is_set': False,
                        'original_name': obj_name,
                        'base_name': obj_name
                    }
                    
                    obj_info = {
                        'name': obj_name,
                        'object': existing_obj,  # å¦‚æœå·²å­˜åœ¨åˆ™ä½¿ç”¨ç°æœ‰ç‰©ä½“
                        'parsed_info': basic_info,
                        'location': (0, 0, 0),
                        'rotation': (0, 0, 0),
                        'scale': (1, 1, 1),
                        'already_imported': existing_obj is not None
                    }
                    
                    objects_info.append(obj_info)
                    
                    if existing_obj:
                        print(f"  âœ“ ç‰©ä½“ '{obj_name}' å·²å­˜åœ¨ï¼Œç›´æ¥å¼•ç”¨")
                    else:
                        print(f"  + ç‰©ä½“ '{obj_name}' éœ€è¦å¯¼å…¥")
                        
                except Exception as e:
                    print(f"å¤‡ç”¨åŠ è½½ {obj_name} æ—¶å‡ºé”™: {e}")
                    continue
            
            print(f"å¤‡ç”¨åŠ è½½å®Œæˆ: å…±åŠ è½½ {len(objects_info)} ä¸ªç‰©ä½“")
        
    except Exception as e:
        print(f"è¯»å–.blendæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return []
    
    return objects_info

def find_matching_objects(source_objects, target_objects):
    """æ‰¾åˆ°åŒ¹é…çš„ç‰©ä½“
    
    Args:
        source_objects (list): æºç‰©ä½“åˆ—è¡¨ï¼ˆå½“å‰é€‰ä¸­çš„ç‰©ä½“ï¼‰
        target_objects (list): ç›®æ ‡ç‰©ä½“åˆ—è¡¨ï¼ˆä».blendæ–‡ä»¶åŠ è½½çš„ç‰©ä½“ï¼‰
        
    Returns:
        dict: åŒ¹é…ç»“æœå­—å…¸
    """
    matches = {}
    
    print(f"\nğŸ” å¼€å§‹åŒ¹é…: æºç‰©ä½“ {len(source_objects)} ä¸ªï¼Œç›®æ ‡ç‰©ä½“ {len(target_objects)} ä¸ª")
    
    for source_obj in source_objects:
        # æ³¨æ„ï¼šsource_objects ç°åœ¨åªåŒ…å«ç½‘æ ¼ç‰©ä½“ï¼Œä½†ä¸ºäº†å®‰å…¨èµ·è§ä¿ç•™æ£€æŸ¥
        if source_obj.type != 'MESH':
            print(f"  âš ï¸ è·³è¿‡éç½‘æ ¼ç‰©ä½“: {source_obj.name} (ç±»å‹: {source_obj.type})")
            continue
            
        source_info = parse_object_name(source_obj.name)
        
        if not source_info['gender'] or not source_info['parts']:
            print(f"  âš ï¸ è·³è¿‡æ— æ•ˆç‰©ä½“: {source_obj.name} (æ€§åˆ«: {source_info['gender']}, éƒ¨ä½: {source_info['parts']})")
            continue
        
        print(f"\n  ğŸ¯ åŒ¹é…æºç‰©ä½“: {source_obj.name}")
        print(f"      æ€§åˆ«: {source_info['gender']}, éƒ¨ä½: {source_info['parts']}")
        
        # å¦‚æœæ˜¯ mouth éƒ¨ä»¶ï¼Œè¿›è¡Œè¯¦ç»†è¯Šæ–­
        if 'mouth' in source_info['parts']:
            print(f"      ğŸ” æ£€æµ‹åˆ° mouth éƒ¨ä»¶ï¼Œè¿›è¡Œè¯¦ç»†è¯Šæ–­...")
            diagnose_object_parsing(source_obj.name)
        
        # æ‰¾åˆ°åŒ¹é…çš„ç›®æ ‡ç‰©ä½“
        matching_targets = []
        best_match_score = 0
        
        for target_obj in target_objects:
            target_info = target_obj['parsed_info']
            
            # æ£€æŸ¥æ€§åˆ«æ˜¯å¦åŒ¹é…
            gender_match = source_info['gender'] == target_info['gender']
            
            if not gender_match:
                print(f"      âŒ æ€§åˆ«ä¸åŒ¹é…: {target_obj['name']} (æº: {source_info['gender']}, ç›®æ ‡: {target_info['gender']})")
                continue
            
            # æ£€æŸ¥éƒ¨ä»¶æ˜¯å¦ç²¾ç¡®åŒ¹é…
            is_exact_match = is_exact_part_match(source_info['parts'], target_info['parts'])
            
            if is_exact_match:
                source_parts = set(source_info['parts'])
                target_parts = set(target_info['parts'])
                exact_matches = source_parts.intersection(target_parts)
                
                print(f"      âœ… ç²¾ç¡®åŒ¹é…: {target_obj['name']} (åŒ¹é…éƒ¨ä»¶: {list(exact_matches)})")
                matching_targets.append(target_obj)
            else:
                source_parts = set(source_info['parts'])
                target_parts = set(target_info['parts'])
                print(f"      âŒ éƒ¨ä½ä¸åŒ¹é…: {target_obj['name']} (æº: {list(source_parts)}, ç›®æ ‡: {list(target_parts)})")
                print(f"         ğŸ’¡ ä¸æ˜¯ç²¾ç¡®åŒ¹é…")
        
        if matching_targets:
            print(f"      ğŸ“Š æ‰¾åˆ° {len(matching_targets)} ä¸ªç²¾ç¡®åŒ¹é…ç›®æ ‡")
        
        if matching_targets:
            matches[source_obj] = matching_targets
            print(f"      âœ… æ‰¾åˆ° {len(matching_targets)} ä¸ªç²¾ç¡®åŒ¹é…ç›®æ ‡ï¼Œå°†è¿›è¡Œæ›¿æ¢")
        else:
            print(f"      â­ï¸ æ— ç²¾ç¡®åŒ¹é…ç›®æ ‡ï¼Œè·³è¿‡å¤„ç†ï¼ˆé¿å…é”™è¯¯æ›¿æ¢ï¼‰")
    
    print(f"\nğŸ“Š åŒ¹é…å®Œæˆ: æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…çš„æºç‰©ä½“")
    
    # æ‰“å°è¯¦ç»†çš„åŒ¹é…å¯¹åº”å…³ç³»
    print(f"\nğŸ”— åŒ¹é…å¯¹åº”å…³ç³»è¯¦æƒ…:")
    print("=" * 80)
    for source_obj, target_objects_list in matches.items():
        source_info = parse_object_name(source_obj.name)
        print(f"\nğŸ“Œ æºç‰©ä½“: {source_obj.name}")
        print(f"   â”œâ”€ æ€§åˆ«: {source_info['gender']}")
        print(f"   â”œâ”€ éƒ¨ä½: {source_info['parts']}")
        print(f"   â”œâ”€ å¥—è£…: {source_info['is_set']}")
        print(f"   â””â”€ åŒ¹é…ç›®æ ‡æ•°é‡: {len(target_objects_list)}")
        
        for i, target_obj in enumerate(target_objects_list, 1):
            target_info = target_obj['parsed_info']
            print(f"      [{i}] ç›®æ ‡: {target_obj['name']}")
            print(f"          â”œâ”€ æ€§åˆ«: {target_info['gender']}")
            print(f"          â”œâ”€ éƒ¨ä½: {target_info['parts']}")
            print(f"          â””â”€ å¥—è£…: {target_info['is_set']}")
    
    print("=" * 80)
    return matches


def validate_object_state(obj):
    """éªŒè¯å¯¹è±¡çŠ¶æ€æ˜¯å¦æœ‰æ•ˆ
    
    Args:
        obj: è¦éªŒè¯çš„å¯¹è±¡
        
    Returns:
        bool: å¯¹è±¡æ˜¯å¦æœ‰æ•ˆ
    """
    try:
        # æ£€æŸ¥å¯¹è±¡æ˜¯å¦ä»ç„¶å­˜åœ¨
        if not obj or obj.name not in bpy.data.objects:
            return False
        
        # æ£€æŸ¥å¯¹è±¡ç±»å‹
        if obj.type != 'MESH':
            return False
            
        # æ£€æŸ¥ç½‘æ ¼æ•°æ®æ˜¯å¦å­˜åœ¨
        if not hasattr(obj, 'data') or not obj.data:
            return False
            
        if obj.data.name not in bpy.data.meshes:
            return False
        
        # å°è¯•è®¿é—®ç½‘æ ¼æ•°æ®ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ•ˆ
        try:
            _ = len(obj.data.vertices)
        except Exception:
            return False
            
        return True
        
    except Exception:
        return False

def safe_mesh_operation(operation_func, *args, **kwargs):
    """å®‰å…¨æ‰§è¡Œç½‘æ ¼æ“ä½œï¼Œå¸¦é”™è¯¯æ¢å¤
    
    Args:
        operation_func: è¦æ‰§è¡Œçš„æ“ä½œå‡½æ•°
        *args: æ“ä½œå‡½æ•°çš„å‚æ•°
        **kwargs: æ“ä½œå‡½æ•°çš„å…³é”®å­—å‚æ•°
        
    Returns:
        tuple: (æˆåŠŸæ ‡å¿—, ç»“æœæˆ–é”™è¯¯ä¿¡æ¯)
    """
    try:
        result = operation_func(*args, **kwargs)
        return True, result
    except Exception as e:
        error_msg = f"ç½‘æ ¼æ“ä½œå¤±è´¥: {str(e)}"
        print(f"âœ— {error_msg}")
        return False, error_msg

def safe_copy_mesh_data(source_mesh, target_mesh, new_name):
    """å®‰å…¨åœ°å¤åˆ¶ç½‘æ ¼æ•°æ®
    
    Args:
        source_mesh: æºç½‘æ ¼å¯¹è±¡
        target_mesh: ç›®æ ‡ç½‘æ ¼å¯¹è±¡
        new_name (str): æ–°ç½‘æ ¼çš„åç§°
        
    Returns:
        bpy.types.Mesh or None: å¤åˆ¶æˆåŠŸè¿”å›æ–°ç½‘æ ¼ï¼Œå¤±è´¥è¿”å›None
    """
    try:
        # å¤šé‡éªŒè¯æºç½‘æ ¼å’Œç›®æ ‡ç½‘æ ¼
        if not source_mesh:
            print(f"âœ— æºç½‘æ ¼ä¸ºç©º")
            return None
            
        if not target_mesh:
            print(f"âœ— ç›®æ ‡ç½‘æ ¼ä¸ºç©º")
            return None
        
        # æ£€æŸ¥ç½‘æ ¼æ˜¯å¦åœ¨æ•°æ®å—ä¸­
        if source_mesh.name not in bpy.data.meshes:
            print(f"âœ— æºç½‘æ ¼ä¸åœ¨æ•°æ®å—ä¸­: {source_mesh.name}")
            return None
            
        if target_mesh.name not in bpy.data.meshes:
            print(f"âœ— ç›®æ ‡ç½‘æ ¼ä¸åœ¨æ•°æ®å—ä¸­: {target_mesh.name}")
            return None
        
        # æ£€æŸ¥ç½‘æ ¼æ˜¯å¦æœ‰æ•ˆï¼ˆé¿å… StructRNA é”™è¯¯ï¼‰
        try:
            # å°è¯•è®¿é—®ç½‘æ ¼çš„åŸºæœ¬å±æ€§
            _ = len(target_mesh.vertices)
            _ = len(target_mesh.polygons)
        except Exception as mesh_error:
            print(f"âœ— ç›®æ ‡ç½‘æ ¼æ— æ•ˆ: {mesh_error}")
            return None
        
        # åˆ›å»ºç½‘æ ¼å‰¯æœ¬
        new_mesh = target_mesh.copy()
        if not new_mesh:
            print(f"âœ— ç½‘æ ¼å¤åˆ¶è¿”å›ç©ºå¯¹è±¡")
            return None
            
        new_mesh.name = new_name
        
        # éªŒè¯æ–°ç½‘æ ¼æ˜¯å¦åˆ›å»ºæˆåŠŸ
        if new_mesh.name not in bpy.data.meshes:
            print(f"âœ— æ–°ç½‘æ ¼æœªæ·»åŠ åˆ°æ•°æ®å—: {new_name}")
            return None
        
        # éªŒè¯æ–°ç½‘æ ¼æ˜¯å¦æœ‰æ•ˆ
        try:
            _ = len(new_mesh.vertices)
            _ = len(new_mesh.polygons)
        except Exception as new_mesh_error:
            print(f"âœ— æ–°ç½‘æ ¼æ— æ•ˆ: {new_mesh_error}")
            # æ¸…ç†æ— æ•ˆçš„ç½‘æ ¼
            try:
                bpy.data.meshes.remove(new_mesh)
            except:
                pass
            return None
            
        return new_mesh
        
    except Exception as e:
        print(f"âœ— ç½‘æ ¼å¤åˆ¶å¼‚å¸¸: {e}")
        return None

def replace_whole_set(source_objects, target_objects, used_targets=None):
    """æ•´å¥—æ›¿æ¢å‡½æ•° - ä»¥æ•´å¥—ä¸ºå•ä½è¿›è¡Œæ›¿æ¢
    
    Args:
        source_objects (list): æºå¥—è£…ä¸­çš„ç‰©ä½“åˆ—è¡¨
        target_objects (list): ç›®æ ‡å¥—è£…ä¸­çš„ç‰©ä½“åˆ—è¡¨
        used_targets (set): å·²ä½¿ç”¨çš„ç›®æ ‡ç‰©ä½“åç§°é›†åˆï¼ˆè¿™é‡Œä¸ä½¿ç”¨ï¼Œå› ä¸ºæ•´å¥—æ›¿æ¢ï¼‰
        
    Returns:
        tuple: (æˆåŠŸæ•°é‡, æ›¿æ¢è¯¦æƒ…)
    """
    if not source_objects or not target_objects:
        return 0, []
    
    successful_replacements = []
    
    # ä¸ºæ¯ä¸ªæºç‰©ä½“æ‰¾åˆ°å¯¹åº”çš„ç›®æ ‡ç‰©ä½“ï¼ˆæŒ‰éƒ¨ä½åŒ¹é…ï¼‰
    print(f"\nğŸ” æ‰¹é‡æ›¿æ¢è¯Šæ–­:")
    for source_obj in source_objects:
        source_parsed = parse_object_name(source_obj.name)
        print(f"\n  ğŸ¯ å¤„ç†æºç‰©ä½“: {source_obj.name}")
        print(f"      æ€§åˆ«: {source_parsed['gender']}, éƒ¨ä½: {source_parsed['parts']}")
        
        matching_targets = []
        
        for target_obj in target_objects:
            target_parsed = target_obj['parsed_info']
            # æ£€æŸ¥æ€§åˆ«å’Œéƒ¨ä½æ˜¯å¦åŒ¹é…ï¼ˆä½¿ç”¨ç²¾ç¡®åŒ¹é…ï¼‰
            gender_match = source_parsed['gender'] == target_parsed['gender']
            parts_match = is_exact_part_match(source_parsed['parts'], target_parsed['parts'])
            
            if gender_match and parts_match:
                print(f"      âœ… ç²¾ç¡®åŒ¹é…: {target_obj['name']} (éƒ¨ä½: {target_parsed['parts']})")
                matching_targets.append(target_obj)
            else:
                if not gender_match:
                    print(f"      âŒ æ€§åˆ«ä¸åŒ¹é…: {target_obj['name']} (æº: {source_parsed['gender']}, ç›®æ ‡: {target_parsed['gender']})")
                elif not parts_match:
                    print(f"      âŒ éƒ¨ä½ä¸åŒ¹é…: {target_obj['name']} (æº: {source_parsed['parts']}, ç›®æ ‡: {target_parsed['parts']})")
        
        if matching_targets:
            # å¯¹äºæ•´å¥—æ›¿æ¢ï¼Œæˆ‘ä»¬é€‰æ‹©ç¬¬ä¸€ä¸ªåŒ¹é…çš„ç›®æ ‡ï¼ˆå› ä¸ºæ•´å¥—å·²ç»ç¡®å®šï¼‰
            # è¿™æ ·å¯ä»¥ç¡®ä¿æ•´å¥—çš„ä¸€è‡´æ€§
            target_obj = matching_targets[0]
            
            # æ‰§è¡Œæ›¿æ¢ï¼ˆè¿™é‡Œéœ€è¦å®ç°å…·ä½“çš„æ›¿æ¢é€»è¾‘ï¼‰
            # ç”±äºreplace_object_with_randomå‡½æ•°æœªå®šä¹‰ï¼Œæˆ‘ä»¬ä½¿ç”¨ç®€åŒ–çš„æ›¿æ¢é€»è¾‘
            try:
                # ä¿å­˜æºç‰©ä½“çš„å˜æ¢ä¿¡æ¯
                original_location = source_obj.location.copy()
                original_rotation = source_obj.rotation_euler.copy()
                original_scale = source_obj.scale.copy()
                
                # å¤åˆ¶ç½‘æ ¼æ•°æ®
                new_mesh = target_obj['object'].data.copy()
                new_mesh.name = f"{target_obj['name']}_replaced_{random.randint(1000, 9999)}"
                
                # æ›¿æ¢ç½‘æ ¼æ•°æ®
                old_mesh = source_obj.data
                source_obj.data = new_mesh
                
                # ä¿æŒæºç‰©ä½“çš„å˜æ¢
                source_obj.location = original_location
                source_obj.rotation_euler = original_rotation
                source_obj.scale = original_scale
                
                # æ›´æ–°ç‰©ä½“åç§°ï¼ˆé¿å…åç§°å†²çªï¼‰
                if target_obj['name'] in bpy.data.objects and bpy.data.objects[target_obj['name']] != source_obj:
                    counter = 1
                    new_name = f"{target_obj['name']}.{counter:03d}"
                    while new_name in bpy.data.objects:
                        counter += 1
                        new_name = f"{target_obj['name']}.{counter:03d}"
                    source_obj.name = new_name
                else:
                    source_obj.name = target_obj['name']
                
                # æ¸…ç†æ—§ç½‘æ ¼
                if old_mesh and old_mesh.users == 0:
                    bpy.data.meshes.remove(old_mesh)
                
                successful_replacements.append((source_obj, target_obj))
                print(f"  âœ“ æ›¿æ¢: {source_obj.name}")
            except Exception as e:
                print(f"  âœ— æ›¿æ¢å¤±è´¥: {e}")
                continue
        else:
            print(f"      â­ï¸ è·³è¿‡ {source_obj.name}ï¼šæ— ç²¾ç¡®åŒ¹é…ç›®æ ‡ï¼ˆé¿å…é”™è¯¯æ›¿æ¢ï¼‰")
    
    print(f"\nğŸ“Š æ•´å¥—æ›¿æ¢å®Œæˆ: æˆåŠŸ {len(successful_replacements)} ä¸ª")
    
    # æ‰“å°æ‰¹é‡æ›¿æ¢çš„è¯¦ç»†å¯¹åº”å…³ç³»
    if successful_replacements:
        print(f"\nğŸ”— æ‰¹é‡æ›¿æ¢å¯¹åº”å…³ç³»è¯¦æƒ…:")
        print("=" * 80)
        for i, (source_obj, target_obj) in enumerate(successful_replacements, 1):
            source_info = parse_object_name(source_obj.name)
            target_info = target_obj['parsed_info']
            
            print(f"\n[{i}] æˆåŠŸæ›¿æ¢:")
            print(f"   ğŸ“Œ æºç‰©ä½“: {source_obj.name}")
            print(f"      â”œâ”€ æ€§åˆ«: {source_info['gender']}")
            print(f"      â”œâ”€ éƒ¨ä½: {source_info['parts']}")
            print(f"      â””â”€ å¥—è£…: {source_info['is_set']}")
            
            print(f"   ğŸ¯ ç›®æ ‡ç‰©ä½“: {target_obj['name']}")
            print(f"      â”œâ”€ æ€§åˆ«: {target_info['gender']}")
            print(f"      â”œâ”€ éƒ¨ä½: {target_info['parts']}")
            print(f"      â””â”€ å¥—è£…: {target_info['is_set']}")
            
            print(f"   âœ… çŠ¶æ€: æ›¿æ¢æˆåŠŸ")
        print("=" * 80)
    
    return len(successful_replacements), successful_replacements

def calculate_replacement_plan(source_objects, target_objects, used_targets=None, enable_set_replacement=False):
    """è®¡ç®—æ›¿æ¢è®¡åˆ’ï¼Œç¡®å®šæ¯ä¸ªæºç‰©ä½“è¦æ›¿æ¢æˆå“ªä¸ªç›®æ ‡ç‰©ä½“
    
    Args:
        source_objects (list): æºç‰©ä½“åˆ—è¡¨
        target_objects (list): ç›®æ ‡ç‰©ä½“åˆ—è¡¨
        used_targets (set): å·²ä½¿ç”¨çš„ç›®æ ‡ç‰©ä½“åç§°é›†åˆ
        enable_set_replacement (bool): æ˜¯å¦å¯ç”¨å¥—è£…æ›¿æ¢æ¨¡å¼
        
    Returns:
        list: æ›¿æ¢è®¡åˆ’åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« (source_obj, target_obj)
    """
    replacement_plan = []
    
    print(f"\nğŸ” å¼€å§‹è®¡ç®—æ›¿æ¢è®¡åˆ’...")
    print(f"  æºç‰©ä½“æ•°é‡: {len(source_objects)}")
    print(f"  ç›®æ ‡ç‰©ä½“æ•°é‡: {len(target_objects)}")
    print(f"  å¥—è£…æ›¿æ¢æ¨¡å¼: {enable_set_replacement}")
    
    # åˆ†ææºç‰©ä½“
    print(f"\nğŸ“‹ æºç‰©ä½“åˆ†æ:")
    for i, source_obj in enumerate(source_objects, 1):
        source_info = parse_object_name(source_obj.name)
        print(f"  [{i}] {source_obj.name}")
        print(f"      æ€§åˆ«: {source_info['gender']}, éƒ¨ä½: {source_info['parts']}, å¥—è£…: {source_info['is_set']}")
    
    # åˆ†æç›®æ ‡ç‰©ä½“
    print(f"\nğŸ¯ ç›®æ ‡ç‰©ä½“åˆ†æ:")
    for i, target in enumerate(target_objects, 1):
        print(f"  [{i}] {target['name']}")
        print(f"      æ€§åˆ«: {target['parsed_info']['gender']}, éƒ¨ä½: {target['parsed_info']['parts']}, å¥—è£…: {target['parsed_info']['is_set']}")
    
    if enable_set_replacement:
        # æ™ºèƒ½å¥—è£…æ›¿æ¢æ¨¡å¼
        print(f"\nğŸ” æ™ºèƒ½å¥—è£…æ›¿æ¢æ¨¡å¼:")
        print("=" * 60)
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå•é€‰æ¨¡å¼
        if len(source_objects) == 1:
            source_obj = source_objects[0]
            source_parsed = parse_object_name(source_obj.name)
            
            print(f"ğŸ¯ å•é€‰æ¨¡å¼: {source_obj.name}")
            print(f"   æ€§åˆ«: {source_parsed['gender']}, éƒ¨ä½: {source_parsed['parts']}")
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºèº«ä½“éƒ¨ä»¶ï¼ˆä¸Šèº«ã€ä¸‹èº«ã€å¤´å‘ï¼‰
            if any(part in source_parsed['parts'] for part in ['upper', 'lower', 'hair']):
                print(f"   æ£€æµ‹åˆ°èº«ä½“éƒ¨ä»¶ï¼Œæ™ºèƒ½å¥—è£…æ›¿æ¢...")
                
                # æ™ºèƒ½èº«ä½“éƒ¨ä»¶æ›¿æ¢é€»è¾‘
                target_obj = smart_body_part_replacement(source_obj, source_parsed, target_objects)
                
                if target_obj:
                    replacement_plan.append((source_obj, target_obj))
                    print(f"   âœ… æ™ºèƒ½æ›¿æ¢æˆåŠŸ: {source_obj.name} -> {target_obj['name']}")
                else:
                    print(f"   â­ï¸ è·³è¿‡ {source_obj.name}ï¼šæ— åŒ¹é…ç›®æ ‡")
                
                return replacement_plan
        
        # å¤šé€‰æ¨¡å¼ï¼šæ™ºèƒ½å¥—è£…æ›¿æ¢
        print(f"ğŸ¯ å¤šé€‰æ¨¡å¼ï¼Œæ™ºèƒ½å¥—è£…æ›¿æ¢")
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨å¥—è£…æ›¿æ¢
        enable_set_replacement = bpy.context.scene.enable_set_replacement
        print(f"   å¥—è£…æ›¿æ¢æ¨¡å¼: {'å¯ç”¨' if enable_set_replacement else 'ç¦ç”¨'}")
        
        if enable_set_replacement:
            # ä½¿ç”¨æ–°çš„æ™ºèƒ½å¤šé€‰æ›¿æ¢é€»è¾‘ï¼ˆæŒ‰é¡¶çº§çˆ¶çº§åˆ†ç»„ï¼‰
            replacement_plan = smart_multi_selection_replacement(source_objects, target_objects)
        else:
            # æ™®é€šæ›¿æ¢æ¨¡å¼ - ä½¿ç”¨ç²¾ç¡®åŒ¹é…
            matches = find_matching_objects(source_objects, target_objects)
            
            print(f"\nğŸ”„ å¤„ç†åŒ¹é…ç»“æœ:")
            for source_obj, target_obj in matches:
                replacement_plan.append((source_obj, target_obj))
                print(f"   âœ… ç²¾ç¡®åŒ¹é…: {source_obj.name} -> {target_obj['name']}")
            
            # å¤„ç†æœªåŒ¹é…çš„ç‰©ä½“
            matched_sources = {match[0] for match in matches}
            unmatched_objects = [obj for obj in source_objects if obj not in matched_sources]
            
            print(f"\nâš ï¸ æœªåŒ¹é…çš„ç‰©ä½“æ•°é‡: {len(unmatched_objects)}")
            for source_obj in unmatched_objects:
                source_parsed = parse_object_name(source_obj.name)
                target_obj = find_matching_random_target(
                    source_parsed['gender'], 
                    source_parsed['parts'], 
                    target_objects
                )
                if target_obj:
                    replacement_plan.append((source_obj, target_obj))
                    print(f"   ğŸ¯ éšæœºæ›¿æ¢: {source_obj.name} -> {target_obj['name']}")
                else:
                    print(f"   â­ï¸ è·³è¿‡: {source_obj.name}")
    else:
        # æ™®é€šæ›¿æ¢æ¨¡å¼ - ä½¿ç”¨ç²¾ç¡®åŒ¹é…
        matches = find_matching_objects(source_objects, target_objects)
        
        print(f"\nğŸ”„ å¤„ç†åŒ¹é…ç»“æœ:")
        for source_obj, target_objects_list in matches.items():
            if target_objects_list:
                # åªé€‰æ‹©ç²¾ç¡®åŒ¹é…çš„ç›®æ ‡ç‰©ä½“
                target_obj = weighted_random_choice(target_objects_list, used_targets)
                if target_obj:
                    replacement_plan.append((source_obj, target_obj))
                    print(f"  âœ… è®¡åˆ’æ›¿æ¢: {source_obj.name} -> {target_obj['name']}")
                else:
                    print(f"  â­ï¸ è·³è¿‡ {source_obj.name}ï¼šæ— å¯ç”¨ç›®æ ‡ç‰©ä½“")
            else:
                print(f"  â­ï¸ è·³è¿‡ {source_obj.name}ï¼šæ— ç²¾ç¡®åŒ¹é…ç›®æ ‡")
        
        # æ£€æŸ¥æœªåŒ¹é…çš„æºç‰©ä½“
        matched_source_names = {obj.name for obj in matches.keys()}
        for source_obj in source_objects:
            if source_obj.name not in matched_source_names:
                print(f"  â­ï¸ è·³è¿‡ {source_obj.name}ï¼šæ— ä»»ä½•åŒ¹é…ç›®æ ‡")
    
    print(f"\nğŸ“Š æ›¿æ¢è®¡åˆ’ç»Ÿè®¡:")
    print(f"  è®¡åˆ’æ›¿æ¢æ•°é‡: {len(replacement_plan)}")
    print(f"  æœªåŒ¹é…æºç‰©ä½“: {len(source_objects) - len(replacement_plan)}")
    
    # æ‰“å°è¯¦ç»†çš„æ›¿æ¢è®¡åˆ’å¯¹åº”å…³ç³»
    if replacement_plan:
        print(f"\nğŸ¯ æœ€ç»ˆæ›¿æ¢è®¡åˆ’è¯¦æƒ…:")
        print("=" * 80)
        for i, (source_obj, target_obj) in enumerate(replacement_plan, 1):
            source_info = parse_object_name(source_obj.name)
            target_info = target_obj['parsed_info']
            
            print(f"\n[{i}] æ›¿æ¢è®¡åˆ’:")
            print(f"   ğŸ“Œ æºç‰©ä½“: {source_obj.name}")
            print(f"      â”œâ”€ æ€§åˆ«: {source_info['gender']}")
            print(f"      â”œâ”€ éƒ¨ä½: {source_info['parts']}")
            print(f"      â””â”€ å¥—è£…: {source_info['is_set']}")
            
            print(f"   ğŸ¯ ç›®æ ‡ç‰©ä½“: {target_obj['name']}")
            print(f"      â”œâ”€ æ€§åˆ«: {target_info['gender']}")
            print(f"      â”œâ”€ éƒ¨ä½: {target_info['parts']}")
            print(f"      â””â”€ å¥—è£…: {target_info['is_set']}")
            
            # æ£€æŸ¥åŒ¹é…ä¸€è‡´æ€§
            gender_match = source_info['gender'] == target_info['gender']
            parts_match = is_exact_part_match(source_info['parts'], target_info['parts'])
            
            if gender_match and parts_match:
                print(f"   âœ… åŒ¹é…çŠ¶æ€: å®Œå…¨åŒ¹é…")
            else:
                print(f"   âŒ åŒ¹é…çŠ¶æ€: ä¸åŒ¹é…")
                if not gender_match:
                    print(f"      â””â”€ æ€§åˆ«ä¸åŒ¹é…: {source_info['gender']} â‰  {target_info['gender']}")
                if not parts_match:
                    print(f"      â””â”€ éƒ¨ä½ä¸åŒ¹é…: {source_info['parts']} â‰  {target_info['parts']}")
        
        print("=" * 80)
    
    # éªŒè¯æ›¿æ¢è®¡åˆ’çš„ä¸€è‡´æ€§
    if replacement_plan:
        validate_replacement_consistency(replacement_plan)
    
    return replacement_plan

def import_target_objects(replacement_plan, file_path):
    """æ‰¹é‡å¯¼å…¥ç›®æ ‡ç‰©ä½“åˆ°éšè—é›†åˆ
    
    Args:
        replacement_plan (list): æ›¿æ¢è®¡åˆ’
        file_path (str): æºæ–‡ä»¶è·¯å¾„
        
    Returns:
        dict: å¯¼å…¥çš„ç‰©ä½“æ˜ å°„ {target_name: imported_object}
    """
    imported_objects = {}
    unique_targets = set()
    
    # æ”¶é›†æ‰€æœ‰éœ€è¦å¯¼å…¥çš„ç›®æ ‡ç‰©ä½“åç§°
    for source_obj, target_obj in replacement_plan:
        unique_targets.add(target_obj['name'])
    
    print(f"å‡†å¤‡å¯¼å…¥ {len(unique_targets)} ä¸ªç›®æ ‡ç‰©ä½“")
    
    # ç¡®ä¿éšè—é›†åˆå­˜åœ¨
    hidden_collection = create_hidden_import_collection()
    
    # æ‰¹é‡å¯¼å…¥
    for target_name in unique_targets:
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing_obj = check_object_exists_in_hidden_collection(target_name)
            if existing_obj:
                imported_objects[target_name] = existing_obj
                print(f"  âœ“ å·²å­˜åœ¨ï¼Œç›´æ¥å¼•ç”¨: {target_name}")
                continue
            
            # å¯¼å…¥æ–°ç‰©ä½“
            bpy.ops.wm.append(
                filepath=file_path,
                directory=file_path + "/Object/",
                filename=target_name
            )
            
            if target_name in bpy.data.objects:
                imported_obj = bpy.data.objects[target_name]
                
                # éªŒè¯å¯¼å…¥çš„ç‰©ä½“
                is_valid = log_imported_object_validation(target_name, imported_obj, "  ")
                if not is_valid:
                    print(f"  âœ— å¯¼å…¥çš„ç‰©ä½“æ— æ•ˆ: {target_name}")
                    continue
                
                # å°†ç‰©ä½“ç§»åŠ¨åˆ°éšè—é›†åˆ
                # å…ˆä»å½“å‰é›†åˆä¸­ç§»é™¤
                for collection in imported_obj.users_collection:
                    collection.objects.unlink(imported_obj)
                
                # æ·»åŠ åˆ°éšè—é›†åˆ
                hidden_collection.objects.link(imported_obj)
                
                # æ ‡è®°ä¸ºå¯¼å…¥çš„ç‰©ä½“
                imported_obj['is_imported_temp'] = True
                imported_obj['is_in_hidden_collection'] = True
                
                imported_objects[target_name] = imported_obj
                print(f"  âœ“ å¯¼å…¥åˆ°éšè—é›†åˆ: {target_name}")
            else:
                print(f"  âœ— å¯¼å…¥å¤±è´¥: {target_name}")
        except Exception as e:
            print(f"  âœ— å¯¼å…¥é”™è¯¯: {target_name} - {e}")
    
    print(f"\nğŸ“Š å¯¼å…¥ç»Ÿè®¡:")
    print(f"  æ€»ç›®æ ‡æ•°: {len(unique_targets)}")
    print(f"  æˆåŠŸå¯¼å…¥: {len(imported_objects)}")
    print(f"  å¤±è´¥æ•°é‡: {len(unique_targets) - len(imported_objects)}")
    
    return imported_objects

def execute_replacements(replacement_plan, imported_objects):
    """æ‰§è¡Œæ›¿æ¢æ“ä½œ
    
    Args:
        replacement_plan (list): æ›¿æ¢è®¡åˆ’
        imported_objects (dict): å¯¼å…¥çš„ç‰©ä½“æ˜ å°„
        
    Returns:
        int: æˆåŠŸæ›¿æ¢çš„æ•°é‡
    """
    successful_replacements = 0
    
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨è¯Šæ–­
    scene = bpy.context.scene
    enable_diagnostics = getattr(scene, 'enable_replacement_diagnostics', False)
    
    if enable_diagnostics:
        print(f"\nğŸ” å¼€å§‹æ‰§è¡Œ {len(replacement_plan)} ä¸ªæ›¿æ¢æ“ä½œ")
        print("=" * 60)
    
    for i, (source_obj, target_obj) in enumerate(replacement_plan, 1):
        obj_name = source_obj.name if source_obj else "Unknown"
        target_name = target_obj['name']
        
        if enable_diagnostics:
            print(f"\n[{i}/{len(replacement_plan)}] å¤„ç†ç‰©ä½“: {obj_name}")
            print("-" * 40)
        
        try:
            # æ­¥éª¤1: éªŒè¯æºç‰©ä½“
            log_replacement_step("éªŒè¯æºç‰©ä½“", obj_name, "æ£€æŸ¥ç‰©ä½“æœ‰æ•ˆæ€§")
            if not source_obj or not hasattr(source_obj, 'name') or source_obj.name not in bpy.data.objects:
                log_replacement_step("è·³è¿‡", obj_name, "æºç‰©ä½“æ— æ•ˆæˆ–ä¸å­˜åœ¨")
                continue
            
            source_obj = bpy.data.objects[source_obj.name]
            before_state = snapshot_object_state(source_obj)
            log_object_state(obj_name, before_state, "æ›¿æ¢å‰ ")
            
            # æ­¥éª¤2: æ£€æŸ¥ç›®æ ‡ç‰©ä½“
            log_replacement_step("æ£€æŸ¥ç›®æ ‡", obj_name, f"ç›®æ ‡: {target_name}")
            if target_name not in imported_objects:
                log_replacement_step("é”™è¯¯", obj_name, f"ç›®æ ‡ç‰©ä½“ '{target_name}' æœªå¯¼å…¥")
                print(f"  âŒ å¯ç”¨ç›®æ ‡ç‰©ä½“: {list(imported_objects.keys())}")
                continue
            
            target_object = imported_objects[target_name]
            log_replacement_step("è·å–ç›®æ ‡", obj_name, f"ç›®æ ‡ç‰©ä½“: {target_object.name}")
            
            # æ­¥éª¤2.5: éªŒè¯ç›®æ ‡ç‰©ä½“
            is_target_valid = log_imported_object_validation(target_name, target_object, "  ")
            if not is_target_valid:
                log_replacement_step("é”™è¯¯", obj_name, f"ç›®æ ‡ç‰©ä½“ '{target_name}' éªŒè¯å¤±è´¥")
                continue
            
            # æ­¥éª¤3: ä¿å­˜å˜æ¢ä¿¡æ¯
            log_replacement_step("ä¿å­˜å˜æ¢", obj_name, "ä¿å­˜ä½ç½®ã€æ—‹è½¬ã€ç¼©æ”¾")
            original_location = source_obj.location.copy()
            original_rotation = source_obj.rotation_euler.copy()
            original_scale = source_obj.scale.copy()
            
            # æ­¥éª¤4: ç›´æ¥å¼•ç”¨ç›®æ ‡ç½‘æ ¼æ•°æ®ï¼ˆä¸åˆ›å»ºæ–°ç½‘æ ¼ï¼‰
            log_replacement_step("å¼•ç”¨ç½‘æ ¼", obj_name, f"ç›´æ¥å¼•ç”¨ {target_object.data.name}")
            old_mesh = source_obj.data
            source_obj.data = target_object.data
            log_replacement_step("ç½‘æ ¼å¼•ç”¨å®Œæˆ", obj_name, f"å¼•ç”¨ç½‘æ ¼: {source_obj.data.name}")
            
            # æ­¥éª¤5: æ¢å¤å˜æ¢
            log_replacement_step("æ¢å¤å˜æ¢", obj_name, "æ¢å¤ä½ç½®ã€æ—‹è½¬ã€ç¼©æ”¾")
            source_obj.location = original_location
            source_obj.rotation_euler = original_rotation
            source_obj.scale = original_scale
            
            # æ­¥éª¤6: æ›´æ–°ç‰©ä½“åç§°
            log_replacement_step("æ›´æ–°åç§°", obj_name, "é¿å…åç§°å†²çª")
            old_name = source_obj.name
            if target_name in bpy.data.objects and bpy.data.objects[target_name] != source_obj:
                counter = 1
                new_name = f"{target_name}.{counter:03d}"
                while new_name in bpy.data.objects:
                    counter += 1
                    new_name = f"{target_name}.{counter:03d}"
                source_obj.name = new_name
            else:
                source_obj.name = target_name
            log_replacement_step("åç§°æ›´æ–°å®Œæˆ", obj_name, f"æ–°åç§°: {source_obj.name}")
            
            # æ­¥éª¤7: æ¸…ç†æ—§ç½‘æ ¼
            log_replacement_step("æ¸…ç†æ—§ç½‘æ ¼", obj_name, f"æ£€æŸ¥ {old_mesh.name} ä½¿ç”¨æƒ…å†µ")
            if old_mesh and old_mesh.users == 0:
                bpy.data.meshes.remove(old_mesh)
                log_replacement_step("æ—§ç½‘æ ¼å·²åˆ é™¤", obj_name, f"åˆ é™¤ {old_mesh.name}")
            else:
                log_replacement_step("ä¿ç•™æ—§ç½‘æ ¼", obj_name, f"{old_mesh.name} ä»è¢« {old_mesh.users} ä¸ªå¯¹è±¡ä½¿ç”¨")
            
            # æ­¥éª¤8: æ£€æŸ¥æ›¿æ¢åçŠ¶æ€
            after_state = snapshot_object_state(source_obj)
            log_object_state(source_obj.name, after_state, "æ›¿æ¢å ")
            
            # æ­¥éª¤9: å¯¹æ¯”çŠ¶æ€å·®å¼‚
            if enable_diagnostics:
                diff_result = diff_states(before_state, after_state, obj_name)
                print(f"ğŸ“Š çŠ¶æ€å¯¹æ¯”: {diff_result}")
            
            # æ­¥éª¤10: å®‰å…¨æ£€æŸ¥ - å¦‚æœå¯¹è±¡æœªé“¾æ¥åˆ°ä»»ä½•é›†åˆï¼Œé‡æ–°é“¾æ¥
            if after_state.get('exists', True) and after_state.get('collection_count', 0) == 0:
                log_replacement_step("å®‰å…¨ä¿®å¤", source_obj.name, "å¯¹è±¡æœªé“¾æ¥åˆ°é›†åˆï¼Œé‡æ–°é“¾æ¥åˆ°åœºæ™¯æ ¹é›†åˆ")
                try:
                    bpy.context.scene.collection.objects.link(source_obj)
                    fixed_state = snapshot_object_state(source_obj)
                    log_object_state(source_obj.name, fixed_state, "ä¿®å¤å ")
                    if enable_diagnostics:
                        print(f"âœ… [{source_obj.name}] å·²é‡æ–°é“¾æ¥åˆ°åœºæ™¯æ ¹é›†åˆ")
                except Exception as fix_e:
                    if enable_diagnostics:
                        print(f"âŒ [{source_obj.name}] é‡æ–°é“¾æ¥å¤±è´¥: {fix_e}")
            
            log_replacement_step("æ›¿æ¢å®Œæˆ", source_obj.name, f"æˆåŠŸ: {old_name} -> {target_name}")
            successful_replacements += 1
            
        except Exception as e:
            log_replacement_step("æ›¿æ¢å¤±è´¥", obj_name, f"é”™è¯¯: {e}")
            # å³ä½¿å¤±è´¥ä¹Ÿè¦æ£€æŸ¥çŠ¶æ€
            try:
                error_state = snapshot_object_state(source_obj)
                log_object_state(obj_name, error_state, "é”™è¯¯å ")
            except:
                if enable_diagnostics:
                    print(f"âŒ [{obj_name}] æ— æ³•è·å–é”™è¯¯åçŠ¶æ€")
            continue
    
    if enable_diagnostics:
        print(f"\n{'=' * 60}")
        print(f"ğŸ¯ æ›¿æ¢æ“ä½œå®Œæˆ: {successful_replacements}/{len(replacement_plan)} æˆåŠŸ")
    else:
        print(f"æ›¿æ¢å®Œæˆ: {successful_replacements}/{len(replacement_plan)} æˆåŠŸ")
    
    # éªŒè¯æ›¿æ¢ç»“æœ
    if replacement_plan:
        validate_replacement_results(replacement_plan)
    
    # æ‰“å°æ‰§è¡Œç»“æœçš„è¯¦ç»†å¯¹åº”å…³ç³»
    print(f"\nğŸ”— æ‰§è¡Œç»“æœå¯¹åº”å…³ç³»è¯¦æƒ…:")
    print("=" * 80)
    print(f"ğŸ“Š æ‰§è¡Œç»Ÿè®¡:")
    print(f"   â”œâ”€ è®¡åˆ’æ›¿æ¢æ•°é‡: {len(replacement_plan)}")
    print(f"   â”œâ”€ æˆåŠŸæ›¿æ¢æ•°é‡: {successful_replacements}")
    print(f"   â””â”€ æˆåŠŸç‡: {(successful_replacements/len(replacement_plan)*100):.1f}%" if replacement_plan else "0%")
    
    if replacement_plan:
        print(f"\nğŸ“‹ è¯¦ç»†æ‰§è¡Œç»“æœ:")
        for i, (source_obj, target_obj) in enumerate(replacement_plan, 1):
            source_info = parse_object_name(source_obj.name)
            target_info = target_obj['parsed_info']
            
            print(f"\n[{i}] æ‰§è¡Œç»“æœ:")
            print(f"   ğŸ“Œ æºç‰©ä½“: {source_obj.name}")
            print(f"      â”œâ”€ æ€§åˆ«: {source_info['gender']}")
            print(f"      â”œâ”€ éƒ¨ä½: {source_info['parts']}")
            print(f"      â””â”€ å¥—è£…: {source_info['is_set']}")
            
            print(f"   ğŸ¯ ç›®æ ‡ç‰©ä½“: {target_obj['name']}")
            print(f"      â”œâ”€ æ€§åˆ«: {target_info['gender']}")
            print(f"      â”œâ”€ éƒ¨ä½: {target_info['parts']}")
            print(f"      â””â”€ å¥—è£…: {target_info['is_set']}")
            
            print(f"   âœ… çŠ¶æ€: æ‰§è¡Œå®Œæˆ")
    
    print("=" * 80)
    
    return successful_replacements

def cleanup_imported_objects(imported_objects):
    """æ¸…ç†å¯¼å…¥çš„ä¸´æ—¶ç‰©ä½“ï¼ˆä¸æ¸…ç†éšè—é›†åˆä¸­çš„ç‰©ä½“ï¼‰
    
    Args:
        imported_objects (dict): å¯¼å…¥çš„ç‰©ä½“æ˜ å°„
    """
    removed_count = 0
    for target_name, imported_obj in imported_objects.items():
        try:
            # åªæ¸…ç†ä¸åœ¨éšè—é›†åˆä¸­çš„ä¸´æ—¶ç‰©ä½“
            if (imported_obj.name in bpy.data.objects and 
                not imported_obj.get('is_in_hidden_collection', False)):
                bpy.data.objects.remove(imported_obj, do_unlink=True)
                removed_count += 1
        except Exception as e:
            pass
    
    if removed_count > 0:
        print(f"æ¸…ç†å®Œæˆ: åˆ é™¤äº† {removed_count} ä¸ªä¸´æ—¶ç‰©ä½“")
    
    # æ‰§è¡Œé€’å½’æ¸…ç†
    recursive_cleanup_unused_data()

def find_reference_body_part(source_obj, gender):
    """æŒ‰ç…§ä¼˜å…ˆçº§é¡ºåºæŸ¥æ‰¾å‚è€ƒéƒ¨ä»¶ï¼šä¸Šèº« > ä¸‹èº« > å¤´å‘
    
    Args:
        source_obj: æºç‰©ä½“
        gender: æ€§åˆ«
        
    Returns:
        bpy.types.Object or None: æ‰¾åˆ°çš„å‚è€ƒéƒ¨ä»¶ï¼Œå¦‚æœæ²¡æ‰¾åˆ°è¿”å›None
    """
    print(f"ğŸ” æŸ¥æ‰¾å‚è€ƒéƒ¨ä»¶: æ€§åˆ«={gender}")
    print(f"   ä¼˜å…ˆçº§é¡ºåº: ä¸Šèº« > ä¸‹èº« > å¤´å‘")
    
    # è·å–é¡¶çº§çˆ¶çº§
    top_parent = source_obj
    while top_parent.parent:
        top_parent = top_parent.parent
    
    print(f"   é¡¶çº§çˆ¶çº§: {top_parent.name}")
    
    # éå†é¡¶çº§çˆ¶çº§ä¸‹çš„æ‰€æœ‰å­ç‰©ä½“
    def get_all_children(obj):
        children = []
        for child in obj.children:
            children.append(child)
            children.extend(get_all_children(child))
        return children
    
    all_children = get_all_children(top_parent)
    print(f"   å­ç‰©ä½“æ•°é‡: {len(all_children)}")
    
    # æŒ‰ç…§ä¼˜å…ˆçº§é¡ºåºæŸ¥æ‰¾å‚è€ƒéƒ¨ä»¶
    priority_parts = ['upper', 'lower', 'hair']
    
    for priority_part in priority_parts:
        print(f"   ğŸ” æŸ¥æ‰¾ {priority_part} éƒ¨ä»¶...")
        
        for child in all_children:
            if child == source_obj:
                continue
                
            if child.type != 'MESH':
                continue
                
            child_parsed = parse_object_name(child.name)
            
            # æ£€æŸ¥æ€§åˆ«å’Œéƒ¨ä½æ˜¯å¦åŒ¹é…
            if (child_parsed['gender'] == gender and 
                priority_part in child_parsed['parts']):
                print(f"   âœ… æ‰¾åˆ°å‚è€ƒéƒ¨ä»¶: {child.name} (éƒ¨ä½: {priority_part})")
                return child
        
        print(f"   âŒ æœªæ‰¾åˆ° {priority_part} éƒ¨ä»¶")
    
    print(f"   âŒ æœªæ‰¾åˆ°ä»»ä½•å‚è€ƒéƒ¨ä»¶")
    return None

def find_matching_target_set(reference_parsed, target_objects):
    """æŸ¥æ‰¾åŒ¹é…çš„ç›®æ ‡å¥—è£…
    
    Args:
        reference_parsed: å‚è€ƒéƒ¨ä»¶çš„è§£æä¿¡æ¯
        target_objects: ç›®æ ‡ç‰©ä½“åˆ—è¡¨
        
    Returns:
        dict or None: åŒ¹é…çš„ç›®æ ‡å¥—è£…ç‰©ä½“
    """
    print(f"ğŸ” æŸ¥æ‰¾åŒ¹é…çš„ç›®æ ‡å¥—è£…:")
    print(f"   å‚è€ƒéƒ¨ä»¶æ€§åˆ«: {reference_parsed['gender']}")
    print(f"   å‚è€ƒéƒ¨ä»¶å¥—è£…: {reference_parsed['is_set']}")
    
    # æŒ‰å¥—è£…åˆ†ç»„ç›®æ ‡ç‰©ä½“
    target_sets = group_objects_by_sets_smart([{'name': obj['name'], 'parsed_info': obj['parsed_info']} for obj in target_objects])
    
    matching_sets = []
    
    for target_set_id, target_set_info in target_sets.items():
        # æ£€æŸ¥æ€§åˆ«åŒ¹é…
        if target_set_info['gender'] != reference_parsed['gender']:
            continue
        
        matching_sets.append((target_set_id, target_set_info))
        print(f"   âœ… æ‰¾åˆ°åŒ¹é…å¥—è£…: {target_set_id}")
    
    if matching_sets:
        # éšæœºé€‰æ‹©ä¸€ä¸ªåŒ¹é…çš„å¥—è£…
        target_set_id, target_set_info = random.choice(matching_sets)
        print(f"   ğŸ¯ é€‰æ‹©ç›®æ ‡å¥—è£…: {target_set_id}")
        
        # è¿”å›å¥—è£…ä¸­çš„ç¬¬ä¸€ä¸ªç‰©ä½“ä½œä¸ºä»£è¡¨
        if target_set_info['objects']:
            first_obj = target_set_info['objects'][0]
            if hasattr(first_obj, 'name'):
                obj_name = first_obj.name
            else:
                obj_name = first_obj['name']
            
            # åœ¨target_objectsä¸­æ‰¾åˆ°å¯¹åº”çš„ç‰©ä½“
            for target_obj in target_objects:
                if target_obj['name'] == obj_name:
                    return target_obj
    
    print(f"   âŒ æœªæ‰¾åˆ°åŒ¹é…çš„ç›®æ ‡å¥—è£…")
    return None

def find_matching_part_in_set(source_obj, target_set_obj, target_objects):
    """åœ¨ç›®æ ‡å¥—è£…ä¸­æŸ¥æ‰¾åŒ¹é…çš„éƒ¨ä»¶
    
    Args:
        source_obj: æºç‰©ä½“
        target_set_obj: ç›®æ ‡å¥—è£…ä»£è¡¨ç‰©ä½“
        target_objects: ç›®æ ‡ç‰©ä½“åˆ—è¡¨
        
    Returns:
        dict or None: åŒ¹é…çš„ç›®æ ‡ç‰©ä½“
    """
    source_parsed = parse_object_name(source_obj.name)
    target_set_parsed = parse_object_name(target_set_obj['name'])
    
    print(f"ğŸ” åœ¨ç›®æ ‡å¥—è£…ä¸­æŸ¥æ‰¾åŒ¹é…éƒ¨ä»¶:")
    print(f"   æºéƒ¨ä»¶: {source_obj.name} (éƒ¨ä½: {source_parsed['parts']})")
    print(f"   ç›®æ ‡å¥—è£…: {target_set_obj['name']}")
    
    # è·å–ç›®æ ‡å¥—è£…çš„åŸºç¡€åç§°
    target_base_name = target_set_parsed['base_name']
    
    # æŸ¥æ‰¾ç›®æ ‡å¥—è£…ä¸­çš„æ‰€æœ‰ç‰©ä½“
    target_set_objects = []
    for target_obj in target_objects:
        target_obj_parsed = parse_object_name(target_obj['name'])
        
        # æ£€æŸ¥æ€§åˆ«åŒ¹é…
        if target_obj_parsed['gender'] == source_parsed['gender']:
            # æ£€æŸ¥åŸºç¡€åç§°æ˜¯å¦åŒ¹é…
            target_obj_name_parts = target_obj['name'].split('_')
            target_obj_set_parts = []
            
            for part in target_obj_name_parts:
                part_lower = part.lower()
                if part_lower not in BODY_PART_KEYWORDS + SET_KEYWORDS:
                    target_obj_set_parts.append(part)
            
            if target_obj_set_parts:
                target_obj_base_name = '_'.join(target_obj_set_parts)
            else:
                target_obj_base_name = f"{target_obj_parsed['gender']}_sets"
            
            if target_obj_base_name == target_base_name:
                target_set_objects.append(target_obj)
                print(f"      âœ… æ€§åˆ«å’Œå¥—è£…åŒ¹é…: {target_obj['name']}")
            else:
                print(f"      âŒ å¥—è£…ä¸åŒ¹é…: {target_obj['name']}")
        else:
            print(f"      âŒ æ€§åˆ«ä¸åŒ¹é…: {target_obj['name']}")
    
    print(f"   ç›®æ ‡å¥—è£…ç‰©ä½“æ•°é‡: {len(target_set_objects)}")
    
    # æŸ¥æ‰¾ç²¾ç¡®åŒ¹é…çš„éƒ¨ä»¶
    for target_obj in target_set_objects:
        target_obj_parsed = parse_object_name(target_obj['name'])
        
        # æ£€æŸ¥éƒ¨ä½æ˜¯å¦ä¸¥æ ¼åŒ¹é…
        if is_exact_part_match(source_parsed['parts'], target_obj_parsed['parts']):
            print(f"   âœ… æ‰¾åˆ°ç²¾ç¡®åŒ¹é…: {target_obj['name']}")
            return target_obj
    
    # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œè¿”å›Noneï¼ˆä¸è¿›è¡Œéšæœºé€‰æ‹©ï¼‰
    print(f"   âŒ ç›®æ ‡å¥—è£…ä¸­æ— åŒ¹é…éƒ¨ä»¶")
    return None

def group_objects_by_sets_smart(objects):
    """æ™ºèƒ½å¥—è£…åˆ†ç»„ï¼ˆåŒ…å«ä¸å®Œæ•´çš„å¥—è£…ï¼‰
    
    Args:
        objects (list): ç‰©ä½“åˆ—è¡¨
        
    Returns:
        dict: å¥—è£…åˆ†ç»„ç»“æœ
    """
    sets = {}
    
    for obj in objects:
        # å¤„ç†ç‰©ä½“å¯¹è±¡æˆ–å­—å…¸
        if hasattr(obj, 'name'):
            obj_name = obj.name
            parsed_info = parse_object_name(obj_name)
            parent_name = "NoParent"
        else:
            obj_name = obj['name']
            parsed_info = obj['parsed_info']
            parent_name = "NoParent"
        
        # æ™ºèƒ½å¥—è£…è¯†åˆ«ï¼šåŸºäºsetså…³é”®è¯å’Œæ€§åˆ«è¿›è¡Œåˆ†ç»„
        if parsed_info['gender'] and parsed_info['parts']:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«setså…³é”®è¯
            if parsed_info['is_set']:
                # æå–ç‰©ä½“åç§°ä¸­é™¤äº†éƒ¨ä½å…³é”®è¯ä¹‹å¤–çš„éƒ¨åˆ†ä½œä¸ºå¥—è£…æ ‡è¯†ç¬¦
                name_parts = obj_name.split('_')
                set_parts = []
                
                for part in name_parts:
                    part_lower = part.lower()
                    # ä¿ç•™æ€§åˆ«å…³é”®è¯å’Œéƒ¨ä½å…³é”®è¯ä¹‹å¤–çš„æ‰€æœ‰éƒ¨åˆ†
                    if part_lower not in GENDER_KEYWORDS + BODY_PART_KEYWORDS + SET_KEYWORDS:
                        set_parts.append(part)
                
                # ä½¿ç”¨æ€§åˆ« + é™¤äº†éƒ¨ä½å…³é”®è¯ä»¥å¤–çš„æ‰€æœ‰éƒ¨åˆ†ä½œä¸ºå¥—è£…æ ‡è¯†ç¬¦
                if set_parts:
                    set_id = f"{parsed_info['gender']}_{'_'.join(set_parts)}"
                    base_name = '_'.join(set_parts)
                else:
                    set_id = f"{parsed_info['gender']}_sets"
                    base_name = f"{parsed_info['gender']}_sets"
            else:
                # éå¥—è£…ç‰©ä½“ï¼Œæ¯ä¸ªç‰©ä½“å•ç‹¬åˆ†ç»„
                set_id = f"{parsed_info['gender']}_{parsed_info['parts'][0]}_single"
                base_name = f"{parsed_info['gender']}_{parsed_info['parts'][0]}"
            
            if set_id not in sets:
                sets[set_id] = {
                    'gender': parsed_info['gender'],
                    'base_name': base_name,
                    'parent_name': parent_name,
                    'objects': []
                }
            
            sets[set_id]['objects'].append(obj)
    
    return sets

def find_matching_sets_smart(source_sets, target_sets):
    """æ™ºèƒ½å¥—è£…åŒ¹é…ï¼ˆå…è®¸ä¸å®Œæ•´çš„å¥—è£…ï¼‰
    
    Args:
        source_sets (dict): æºå¥—è£…å­—å…¸
        target_sets (dict): ç›®æ ‡å¥—è£…å­—å…¸
        
    Returns:
        dict: åŒ¹é…çš„å¥—è£…å­—å…¸
    """
    matches = {}
    
    for source_set_id, source_set in source_sets.items():
        source_gender = source_set['gender']
        source_base_name = source_set['base_name']
        
        # å¯»æ‰¾åŒ¹é…çš„ç›®æ ‡å¥—è£…
        matching_target_sets = []
        
        for target_set_id, target_set in target_sets.items():
            target_gender = target_set['gender']
            target_base_name = target_set['base_name']
            
            # æ€§åˆ«å¿…é¡»åŒ¹é…
            if source_gender != target_gender:
                continue
            
            # ä¸èƒ½æ˜¯è‡ªå·±
            if source_set_id == target_set_id:
                continue
            
            # åŸºç¡€åç§°ä¸åŒï¼ˆé¿å…ç›¸åŒå¥—è£…ï¼‰
            if source_base_name == target_base_name:
                continue
            
            matching_target_sets.append((target_set_id, target_set))
        
        if matching_target_sets:
            matches[source_set_id] = matching_target_sets
    
    return matches

def group_objects_by_sets(objects):
    """æŒ‰å¥—è£…åˆ†ç»„ç‰©ä½“ï¼ˆåŸºäºçˆ¶çº§å…³ç³»ï¼‰
    
    Args:
        objects (list): ç‰©ä½“åˆ—è¡¨ï¼ˆå¯ä»¥æ˜¯ç‰©ä½“å¯¹è±¡æˆ–åŒ…å«nameå’Œparsed_infoçš„å­—å…¸ï¼‰
        
    Returns:
        dict: å¥—è£…åˆ†ç»„ç»“æœ
    """
    sets = {}
    
    for obj in objects:
        # å¤„ç†ç‰©ä½“å¯¹è±¡æˆ–å­—å…¸
        if hasattr(obj, 'name'):
            obj_name = obj.name
            parsed_info = parse_object_name(obj_name)
            # è·å–çˆ¶çº§ä¿¡æ¯
            if hasattr(obj, 'parent') and obj.parent:
                parent_name = obj.parent.name
            else:
                parent_name = "NoParent"
        else:
            # å­—å…¸å¯¹è±¡
            obj_name = obj['name']
            parsed_info = obj['parsed_info']
            parent_name = "NoParent"  # å­—å…¸å¯¹è±¡æ²¡æœ‰çˆ¶çº§ä¿¡æ¯
        
        # ä¿®æ”¹å¥—è£…è¯†åˆ«é€»è¾‘ï¼šåŸºäºçˆ¶çº§å…³ç³»å’Œé™¤äº†éƒ¨ä½å…³é”®è¯ä»¥å¤–çš„åç§°éƒ¨åˆ†
        if parsed_info['gender'] and parsed_info['parts']:
            # æå–ç‰©ä½“åç§°ä¸­é™¤äº†éƒ¨ä½å…³é”®è¯ä¹‹å¤–çš„éƒ¨åˆ†ä½œä¸ºå¥—è£…æ ‡è¯†ç¬¦
            name_parts = obj_name.split('_')
            set_parts = []
            
            for part in name_parts:
                part_lower = part.lower()
                # ä¿ç•™æ€§åˆ«å…³é”®è¯å’Œéƒ¨ä½å…³é”®è¯ä¹‹å¤–çš„æ‰€æœ‰éƒ¨åˆ†
                if part_lower not in BODY_PART_KEYWORDS + SET_KEYWORDS:
                    set_parts.append(part)
            
            # ä½¿ç”¨çˆ¶çº§åç§° + é™¤äº†éƒ¨ä½å…³é”®è¯ä»¥å¤–çš„æ‰€æœ‰éƒ¨åˆ†ä½œä¸ºå¥—è£…æ ‡è¯†ç¬¦
            if set_parts:
                set_id = f"{parent_name}_{'_'.join(set_parts)}"
                base_name = '_'.join(set_parts)
            else:
                # å¦‚æœæ²¡æœ‰å…¶ä»–éƒ¨åˆ†ï¼Œä½¿ç”¨çˆ¶çº§åç§° + æ€§åˆ« + ç¬¬ä¸€ä¸ªéƒ¨ä½
                set_id = f"{parent_name}_{parsed_info['gender']}_{parsed_info['parts'][0]}"
                base_name = f"{parsed_info['gender']}_{parsed_info['parts'][0]}"
            
            # è°ƒè¯•ä¿¡æ¯
            print(f"ç‰©ä½“ '{obj_name}' (çˆ¶çº§: {parent_name}) -> å¥—è£…ID: '{set_id}' (æ€§åˆ«: {parsed_info['gender']}, éƒ¨ä½: {parsed_info['parts']})")
            
            if set_id not in sets:
                sets[set_id] = {
                    'gender': parsed_info['gender'],
                    'base_name': base_name,
                    'parent_name': parent_name,
                    'objects': []
                }
            
            sets[set_id]['objects'].append(obj)
    
    return sets

def find_matching_sets(source_sets, target_sets):
    """æ‰¾åˆ°åŒ¹é…çš„å¥—è£…
    
    Args:
        source_sets (dict): æºå¥—è£…å­—å…¸
        target_sets (dict): ç›®æ ‡å¥—è£…å­—å…¸
        
    Returns:
        dict: åŒ¹é…çš„å¥—è£…å­—å…¸
    """
    matches = {}
    
    for source_set_id, source_set in source_sets.items():
        source_gender = source_set['gender']
        source_base_name = source_set['base_name']
        source_parts = set()
        
        # æ”¶é›†æºå¥—è£…ä¸­çš„æ‰€æœ‰éƒ¨ä½
        for obj in source_set['objects']:
            if hasattr(obj, 'name'):
                parsed = parse_object_name(obj.name)
            else:
                parsed = obj['parsed_info']
            source_parts.update(parsed['parts'])
        
        # å¯»æ‰¾åŒ¹é…çš„ç›®æ ‡å¥—è£…
        matching_target_sets = []
        
        for target_set_id, target_set in target_sets.items():
            target_gender = target_set['gender']
            target_base_name = target_set['base_name']
            target_parts = set()
            
            # æ”¶é›†ç›®æ ‡å¥—è£…ä¸­çš„æ‰€æœ‰éƒ¨ä½
            for obj in target_set['objects']:
                if hasattr(obj, 'name'):
                    parsed = parse_object_name(obj.name)
                else:
                    parsed = obj['parsed_info']
                target_parts.update(parsed['parts'])
            
            # æ€§åˆ«å¿…é¡»åŒ¹é…
            if source_gender != target_gender:
                continue
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„éƒ¨ä½åŒ¹é…ï¼ˆè‡³å°‘50%çš„æºéƒ¨ä½åœ¨ç›®æ ‡å¥—è£…ä¸­å­˜åœ¨ï¼‰
            common_parts = source_parts.intersection(target_parts)
            match_ratio = len(common_parts) / len(source_parts) if source_parts else 0
            
            # ç®€åŒ–çš„åŒ¹é…ç­–ç•¥ï¼š
            # 1. æ€§åˆ«å¿…é¡»åŒ¹é…
            # 2. ä¸èƒ½æ˜¯è‡ªå·±
            # 3. åŸºç¡€åç§°ä¸åŒï¼ˆé¿å…ç›¸åŒå¥—è£…ï¼‰
            # 4. æœ‰ä»»æ„éƒ¨ä½åŒ¹é…å³å¯
            if (source_set_id != target_set_id and
                source_base_name != target_base_name and  # åŸºç¡€åç§°å¿…é¡»ä¸åŒ
                len(common_parts) > 0):  # æœ‰ä»»æ„éƒ¨ä½åŒ¹é…å³å¯
                matching_target_sets.append((target_set_id, target_set))
        
        if matching_target_sets:
            # æŒ‰åŒ¹é…ç‡æ’åºï¼Œä¼˜å…ˆé€‰æ‹©åŒ¹é…ç‡é«˜çš„ç›®æ ‡å¥—è£…
            matching_target_sets.sort(key=lambda x: len(source_parts.intersection(set().union(*[parse_object_name(obj.name if hasattr(obj, 'name') else obj['name'])['parts'] for obj in x[1]['objects']]))) / len(source_parts), reverse=True)
            matches[source_set_id] = matching_target_sets
        else:
            pass  # ä¸æ‰“å°æœªåŒ¹é…çš„å¥—è£…
    
    return matches

def recursive_cleanup_unused_data():
    """é€’å½’æ¸…ç†æ‰€æœ‰æ— ç”¨çš„æ•°æ®å—"""
    print("å¼€å§‹é€’å½’æ¸…ç†æ— ç”¨æ•°æ®...")
    
    # æ¸…ç†ç­–ç•¥ï¼šå¤šæ¬¡è¿­ä»£æ¸…ç†ï¼Œç›´åˆ°æ²¡æœ‰æ›´å¤šæ•°æ®å¯ä»¥æ¸…ç†
    max_iterations = 10
    total_cleaned = 0
    
    for iteration in range(max_iterations):
        iteration_cleaned = 0
        
        # 1. æ¸…ç†æ— ç”¨çš„ç½‘æ ¼æ•°æ®
        orphaned_meshes = [mesh for mesh in bpy.data.meshes if mesh.users == 0]
        for mesh in orphaned_meshes:
            try:
                if mesh.name in bpy.data.meshes:
                    bpy.data.meshes.remove(mesh)
                    iteration_cleaned += 1
            except Exception as e:
                print(f"æ¸…ç†ç½‘æ ¼ '{mesh.name}' æ—¶å‡ºé”™: {e}")
        
        # 2. æ¸…ç†æ— ç”¨çš„æè´¨æ•°æ®
        orphaned_materials = [mat for mat in bpy.data.materials if mat.users == 0]
        for mat in orphaned_materials:
            try:
                if mat.name in bpy.data.materials:
                    bpy.data.materials.remove(mat)
                    iteration_cleaned += 1
            except Exception as e:
                print(f"æ¸…ç†æè´¨ '{mat.name}' æ—¶å‡ºé”™: {e}")
        
        # 3. æ¸…ç†æ— ç”¨çš„çº¹ç†æ•°æ®
        orphaned_textures = [tex for tex in bpy.data.textures if tex.users == 0]
        for tex in orphaned_textures:
            try:
                if tex.name in bpy.data.textures:
                    bpy.data.textures.remove(tex)
                    iteration_cleaned += 1
            except Exception as e:
                print(f"æ¸…ç†çº¹ç† '{tex.name}' æ—¶å‡ºé”™: {e}")
        
        # 4. æ¸…ç†æ— ç”¨çš„å›¾åƒæ•°æ®
        orphaned_images = [img for img in bpy.data.images if img.users == 0]
        for img in orphaned_images:
            try:
                if img.name in bpy.data.images:
                    bpy.data.images.remove(img)
                    iteration_cleaned += 1
            except Exception as e:
                print(f"æ¸…ç†å›¾åƒ '{img.name}' æ—¶å‡ºé”™: {e}")
        
        # 5. æ¸…ç†æ— ç”¨çš„èŠ‚ç‚¹ç»„
        orphaned_nodegroups = [ng for ng in bpy.data.node_groups if ng.users == 0]
        for ng in orphaned_nodegroups:
            try:
                if ng.name in bpy.data.node_groups:
                    bpy.data.node_groups.remove(ng)
                    iteration_cleaned += 1
            except Exception as e:
                print(f"æ¸…ç†èŠ‚ç‚¹ç»„ '{ng.name}' æ—¶å‡ºé”™: {e}")
        
        # 6. æ¸…ç†æ— ç”¨çš„åŠ¨ä½œæ•°æ®
        orphaned_actions = [act for act in bpy.data.actions if act.users == 0]
        for act in orphaned_actions:
            try:
                if act.name in bpy.data.actions:
                    bpy.data.actions.remove(act)
                    iteration_cleaned += 1
            except Exception as e:
                print(f"æ¸…ç†åŠ¨ä½œ '{act.name}' æ—¶å‡ºé”™: {e}")
        
        # 7. æ¸…ç†æ— ç”¨çš„é›†åˆ
        orphaned_collections = [col for col in bpy.data.collections if col.users == 0]
        for col in orphaned_collections:
            try:
                if col.name in bpy.data.collections:
                    bpy.data.collections.remove(col)
                    iteration_cleaned += 1
            except Exception as e:
                print(f"æ¸…ç†é›†åˆ '{col.name}' æ—¶å‡ºé”™: {e}")
        
        total_cleaned += iteration_cleaned
        
        # å¦‚æœè¿™ä¸€è½®æ²¡æœ‰æ¸…ç†ä»»ä½•æ•°æ®ï¼Œè¯´æ˜å·²ç»æ¸…ç†å®Œæ¯•
        if iteration_cleaned == 0:
            break
        
        print(f"ç¬¬ {iteration + 1} è½®æ¸…ç†: {iteration_cleaned} ä¸ªæ•°æ®å—")
    
    print(f"é€’å½’æ¸…ç†å®Œæˆ: æ€»å…±æ¸…ç†äº† {total_cleaned} ä¸ªæ— ç”¨æ•°æ®å—")

def final_cleanup_after_replacement():
    """æ›¿æ¢å®Œæˆåçš„æœ€ç»ˆæ¸…ç†ï¼Œåªæ¸…ç†å¯¼å…¥çš„ä¸´æ—¶ç‰©ä½“ï¼Œä¸æ¸…ç†éšè—é›†åˆä¸­çš„ç‰©ä½“"""
    print("å¼€å§‹æœ€ç»ˆæ¸…ç†...")
    
    # å¼ºåˆ¶åƒåœ¾å›æ”¶
    import gc
    gc.collect()
    
    # åªæ¸…ç†æ ‡è®°ä¸ºå¯¼å…¥çš„ä¸´æ—¶ç‰©ä½“ï¼Œä½†ä¸æ¸…ç†éšè—é›†åˆä¸­çš„ç‰©ä½“
    objects_cleaned = 0
    
    for obj in list(bpy.data.objects):
        if (obj.type == 'MESH' and 
            obj.get('is_imported_temp', False) and
            not obj.get('is_in_hidden_collection', False)):  # ä¸æ¸…ç†éšè—é›†åˆä¸­çš„ç‰©ä½“
            try:
                if obj.name in bpy.data.objects:
                    bpy.data.objects.remove(obj, do_unlink=True)
                    objects_cleaned += 1
                    print(f"æ¸…ç†ä¸´æ—¶ç‰©ä½“: {obj.name}")
            except Exception as e:
                print(f"æ¸…ç†ä¸´æ—¶ç‰©ä½“ '{obj.name}' æ—¶å‡ºé”™: {e}")
    
    # å¤šæ¬¡é€’å½’æ¸…ç†æ‰€æœ‰æ•°æ®
    for i in range(3):  # è¿›è¡Œ3è½®æ·±åº¦æ¸…ç†
        recursive_cleanup_unused_data()
    
    # æœ€ç»ˆæ£€æŸ¥ï¼šæ¸…ç†æ‰€æœ‰å­¤ç«‹çš„ç½‘æ ¼
    final_meshes_cleaned = 0
    for mesh in bpy.data.meshes:
        if mesh.users == 0:
            try:
                if mesh.name in bpy.data.meshes:
                    bpy.data.meshes.remove(mesh)
                    final_meshes_cleaned += 1
            except Exception as e:
                print(f"æœ€ç»ˆæ¸…ç†ç½‘æ ¼ '{mesh.name}' æ—¶å‡ºé”™: {e}")
    
    print(f"æœ€ç»ˆæ¸…ç†å®Œæˆ: æ¸…ç†äº† {objects_cleaned} ä¸ªç‰©ä½“, {final_meshes_cleaned} ä¸ªç½‘æ ¼")
    
    # æœ€åä¸€æ¬¡åƒåœ¾å›æ”¶
    gc.collect()

def clean_imported_objects():
    """æ¸…ç†ä¹‹å‰å¯¼å…¥çš„ä¸´æ—¶ç‰©ä½“ï¼Œé¿å…ç´¯ç§¯ï¼ˆä¸æ¸…ç†éšè—é›†åˆä¸­çš„ç‰©ä½“ï¼‰"""
    # åªæ¸…ç†æ ‡è®°ä¸ºå¯¼å…¥çš„ä¸´æ—¶ç‰©ä½“ï¼Œä½†ä¸æ¸…ç†éšè—é›†åˆä¸­çš„ç‰©ä½“
    objects_to_remove = []
    for obj in bpy.data.objects:
        if (obj.type == 'MESH' and 
            obj.get('is_imported_temp', False) and
            not obj.get('is_in_hidden_collection', False)):  # ä¸æ¸…ç†éšè—é›†åˆä¸­çš„ç‰©ä½“
            objects_to_remove.append(obj)
    
    # å®‰å…¨åˆ é™¤ç‰©ä½“
    removed_count = 0
    for obj in objects_to_remove:
        try:
            if obj.name in bpy.data.objects:
                bpy.data.objects.remove(obj, do_unlink=True)
                removed_count += 1
        except Exception as e:
            pass
    
    if removed_count > 0:
        print(f"å·²æ¸…ç† {removed_count} ä¸ªä¸´æ—¶ç‰©ä½“")
    
    # æ‰§è¡Œé€’å½’æ¸…ç†
    recursive_cleanup_unused_data()

def replace_objects_from_file():
    """ä»æ–‡ä»¶æ›¿æ¢ç‰©ä½“çš„ä¸»å‡½æ•°
    
    Returns:
        str: æ›¿æ¢ç»“æœä¿¡æ¯
    """
    # åˆå§‹åŒ–éšæœºæ•°ç§å­
    initialize_random_seed()
    
    # æ¸…ç†ä¹‹å‰å¯¼å…¥çš„ç‰©ä½“
    clean_imported_objects()
    
    # æ·»åŠ å…¨å±€é”™è¯¯å¤„ç†
    try:
        scene = bpy.context.scene
        file_path = scene.replacement_blend_file
        enable_set_replacement = scene.enable_set_replacement
        
        if not file_path:
            return "è¯·å…ˆé€‰æ‹©æ›¿æ¢æºæ–‡ä»¶"
    except Exception as e:
        return f"åˆå§‹åŒ–é”™è¯¯: {str(e)}"
    
    # æ·»åŠ å…¨å±€é”™è¯¯æ¢å¤æœºåˆ¶
    try:
        return execute_replacement()
    except Exception as e:
        print(f"æ›¿æ¢è¿‡ç¨‹ä¸­å‡ºç°ä¸¥é‡é”™è¯¯: {e}")
        # å°è¯•æ¸…ç†å’Œæ¢å¤
        try:
            clean_imported_objects()
            print("å·²æ‰§è¡Œç´§æ€¥æ¸…ç†")
        except:
            pass
        return f"æ›¿æ¢å¤±è´¥: {str(e)}"

def execute_replacement():
    # è·å–åœºæ™¯è®¾ç½®
    scene = bpy.context.scene
    file_path = scene.replacement_blend_file
    enable_set_replacement = scene.enable_set_replacement
    
    # å¤„ç†æ–‡ä»¶è·¯å¾„
    file_path = bpy.path.abspath(file_path)
    print(f"æ£€æŸ¥æ–‡ä»¶è·¯å¾„: {file_path}")
    
    if not os.path.exists(file_path):
        return f"é€‰æ‹©çš„æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
    
    # ä¿å­˜å½“å‰é€‰ä¸­çš„ç‰©ä½“ä¿¡æ¯
    selected_objects = bpy.context.selected_objects
    if not selected_objects:
        return "è¯·å…ˆé€‰æ‹©è¦æ›¿æ¢çš„ç‰©ä½“"
    
    # éªŒè¯é€‰ä¸­çš„ç‰©ä½“æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
    valid_objects = []
    for obj in selected_objects:
        if obj.name in bpy.data.objects and obj.type == 'MESH':
            valid_objects.append(obj)
        else:
            print(f"è·³è¿‡æ— æ•ˆç‰©ä½“: {obj.name} (ç±»å‹: {obj.type})")
    
    if not valid_objects:
        return "é€‰ä¸­çš„ç‰©ä½“ä¸­æ²¡æœ‰æœ‰æ•ˆçš„ç½‘æ ¼ç‰©ä½“"
    
    # ä¿å­˜é€‰ä¸­ç‰©ä½“çš„åç§°ï¼Œé˜²æ­¢æ–‡ä»¶åˆ‡æ¢åä¸¢å¤±å¼•ç”¨
    selected_object_names = [obj.name for obj in valid_objects]
    print(f"è¦æ›¿æ¢çš„ç‰©ä½“: {selected_object_names}")
    
    # ä»æ–‡ä»¶åŠ è½½ç‰©ä½“
    print("æ­£åœ¨ä»æ–‡ä»¶åŠ è½½ç‰©ä½“...")
    target_objects = load_objects_from_blend(file_path)
    if not target_objects:
        return "æ— æ³•ä»æ–‡ä»¶ä¸­åŠ è½½æœ‰æ•ˆçš„ç‰©ä½“ã€‚è¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åŒ…å«ç½‘æ ¼ç‰©ä½“ï¼Œæˆ–ç¡®ä¿ç‰©ä½“å‘½åç¬¦åˆè§„èŒƒï¼ˆæ€§åˆ«_éƒ¨ä½_å…¶ä»–ä¿¡æ¯ï¼‰"
    
    print(f"ä»æ–‡ä»¶ä¸­åŠ è½½äº† {len(target_objects)} ä¸ªç‰©ä½“")
    
    # é‡æ–°è·å–é€‰ä¸­çš„ç‰©ä½“ï¼ˆé˜²æ­¢æ–‡ä»¶åˆ‡æ¢åå¼•ç”¨ä¸¢å¤±ï¼‰
    current_selected_objects = []
    for obj_name in selected_object_names:
        try:
            if obj_name in bpy.data.objects:
                obj = bpy.data.objects[obj_name]
                # å†æ¬¡éªŒè¯ç‰©ä½“æ˜¯å¦æœ‰æ•ˆ
                if (obj and 
                    hasattr(obj, 'type') and 
                    obj.type == 'MESH' and 
                    obj.name in bpy.data.objects):
                    current_selected_objects.append(obj)
                else:
                    print(f"è·³è¿‡æ— æ•ˆç‰©ä½“: {obj_name}")
            else:
                print(f"ç‰©ä½“ä¸å­˜åœ¨: {obj_name}")
        except Exception as e:
            print(f"è·å–ç‰©ä½“ '{obj_name}' æ—¶å‡ºé”™: {e}")
            continue
    
    if not current_selected_objects:
        return "é€‰ä¸­çš„ç‰©ä½“åœ¨å½“å‰åœºæ™¯ä¸­ä¸å­˜åœ¨æˆ–æ— æ•ˆ"
    
    print(f"å‡†å¤‡æ›¿æ¢ {len(current_selected_objects)} ä¸ªç½‘æ ¼ç‰©ä½“:")
    for obj in current_selected_objects:
        print(f"  - {obj.name} ({obj.type})")
    
    replaced_count = 0
    set_replaced_count = 0
    used_targets = set()  # è·Ÿè¸ªå·²ä½¿ç”¨çš„ç›®æ ‡ç‰©ä½“
    
    # è®¡ç®—æ›¿æ¢è®¡åˆ’
    print("è®¡ç®—æ›¿æ¢è®¡åˆ’...")
    replacement_plan = calculate_replacement_plan(current_selected_objects, target_objects, used_targets, enable_set_replacement)
    
    if not replacement_plan:
        return "æ²¡æœ‰æ‰¾åˆ°å¯æ›¿æ¢çš„ç‰©ä½“"
    
    print(f"è®¡åˆ’æ›¿æ¢ {len(replacement_plan)} ä¸ªç‰©ä½“")
    
    # æ‰¹é‡å¯¼å…¥ç›®æ ‡ç‰©ä½“
    print("æ‰¹é‡å¯¼å…¥ç›®æ ‡ç‰©ä½“...")
    imported_objects = import_target_objects(replacement_plan, file_path)
    
    if not imported_objects:
        return "å¯¼å…¥ç›®æ ‡ç‰©ä½“å¤±è´¥"
    
    # æ‰§è¡Œæ›¿æ¢æ“ä½œ
    print("æ‰§è¡Œæ›¿æ¢æ“ä½œ...")
    replaced_count = execute_replacements(replacement_plan, imported_objects)
    
    # è®¾ç½®é€‰ä¸­çŠ¶æ€ï¼šé€‰ä¸­æ‰€æœ‰å·²ç»æ›¿æ¢çš„ç‰©ä½“
    try:
        bpy.ops.object.select_all(action='DESELECT')
        
        # æ”¶é›†æ‰€æœ‰å·²ç»æ›¿æ¢çš„ç‰©ä½“
        replaced_objects = []
        for source_obj, target_obj in replacement_plan:
            if source_obj and source_obj.name in bpy.data.objects:
                replaced_objects.append(source_obj)
                print(f"âœ… é€‰ä¸­å·²æ›¿æ¢ç‰©ä½“: {source_obj.name}")
        
        # é€‰ä¸­æ‰€æœ‰å·²æ›¿æ¢çš„ç‰©ä½“
        for obj in replaced_objects:
            obj.select_set(True)
        
        # è®¾ç½®æ´»åŠ¨ç‰©ä½“ä¸ºç¬¬ä¸€ä¸ªå·²æ›¿æ¢çš„ç‰©ä½“
        if replaced_objects:
            bpy.context.view_layer.objects.active = replaced_objects[0]
            print(f"ğŸ¯ è®¾ç½®æ´»åŠ¨ç‰©ä½“: {replaced_objects[0].name}")
        
        print(f"ğŸ“‹ æœ€ç»ˆé€‰ä¸­çŠ¶æ€: {len(replaced_objects)} ä¸ªå·²æ›¿æ¢ç‰©ä½“")
        
    except Exception as e:
        print(f"âš ï¸ è®¾ç½®é€‰ä¸­çŠ¶æ€æ—¶å‡ºé”™: {e}")
        pass
    
    # è¿”å›ç»“æœ
    if enable_set_replacement:
        return f"å¥—è£…æ›¿æ¢å®Œæˆ: æˆåŠŸæ›¿æ¢äº† {replaced_count} ä¸ªç‰©ä½“"
    else:
        return f"æ›¿æ¢å®Œæˆ: æˆåŠŸæ›¿æ¢äº† {replaced_count} ä¸ªç‰©ä½“"

class mian_OT_ObjectClassifier(bpy.types.Operator):
    """æ ¹æ®åç§°å…³é”®å­—åˆ†ç±»ç‰©ä½“åˆ°é›†åˆ"""
    bl_idname = "object.mian_object_classifier"
    bl_label = "æŒ‰åç§°åˆ†ç±»ç‰©ä½“"
    bl_description = "æ ¹æ®ç‰©ä½“åç§°ä¸­çš„å…³é”®è¯è‡ªåŠ¨åˆ†ç±»åˆ°å¯¹åº”é›†åˆ"
    bl_options = {'REGISTER', 'UNDO'}

    def execute(self, context):
        try:
            result = classify_and_organize_objects()
            self.report({'INFO'}, result)
            return {'FINISHED'}
        except Exception as e:
            self.report({'ERROR'}, f"åˆ†ç±»è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            return {'CANCELLED'}

class mian_OT_ObjectReplacer(bpy.types.Operator):
    """ä».blendæ–‡ä»¶æ›¿æ¢ç‰©ä½“"""
    bl_idname = "object.mian_object_replacer"
    bl_label = "ä»æ–‡ä»¶æ›¿æ¢ç‰©ä½“"
    bl_description = "ä»æŒ‡å®šçš„.blendæ–‡ä»¶ä¸­è¯»å–ç‰©ä½“å¹¶æ›¿æ¢å½“å‰é€‰ä¸­çš„ç‰©ä½“"
    bl_options = {'REGISTER', 'UNDO'}

    def execute(self, context):
        try:
            result = replace_objects_from_file()
            self.report({'INFO'}, result)
            return {'FINISHED'}
        except Exception as e:
            self.report({'ERROR'}, f"æ›¿æ¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            return {'CANCELLED'}

class mian_OT_ManageHiddenCollection(bpy.types.Operator):
    """ç®¡ç†éšè—å¯¼å…¥é›†åˆ"""
    bl_idname = "object.mian_manage_hidden_collection"
    bl_label = "ç®¡ç†éšè—å¯¼å…¥é›†åˆ"
    bl_description = "ç®¡ç†éšè—çš„å¯¼å…¥ç‰©ä½“é›†åˆï¼ŒåŒ…æ‹¬æ˜¾ç¤ºã€éšè—ã€æ¸…ç†ç­‰æ“ä½œ"
    bl_options = {'REGISTER', 'UNDO'}
    
    action: bpy.props.EnumProperty(
        name="æ“ä½œ",
        description="é€‰æ‹©è¦æ‰§è¡Œçš„æ“ä½œ",
        items=[
            ('SHOW', "æ˜¾ç¤ºé›†åˆ", "æ˜¾ç¤ºéšè—çš„å¯¼å…¥é›†åˆ"),
            ('HIDE', "éšè—é›†åˆ", "éšè—å¯¼å…¥é›†åˆ"),
            ('CLEAR', "æ¸…ç©ºé›†åˆ", "æ¸…ç©ºéšè—é›†åˆä¸­çš„æ‰€æœ‰ç‰©ä½“"),
            ('INFO', "æ˜¾ç¤ºä¿¡æ¯", "æ˜¾ç¤ºéšè—é›†åˆçš„ä¿¡æ¯"),
        ],
        default='INFO'
    )
    
    def execute(self, context):
        try:
            hidden_collection = bpy.data.collections.get("Hidden_Imported_Objects")
            
            if not hidden_collection:
                self.report({'WARNING'}, "éšè—å¯¼å…¥é›†åˆä¸å­˜åœ¨")
                return {'CANCELLED'}
            
            if self.action == 'SHOW':
                hidden_collection.hide_viewport = False
                hidden_collection.hide_render = False
                self.report({'INFO'}, "éšè—å¯¼å…¥é›†åˆå·²æ˜¾ç¤º")
                
            elif self.action == 'HIDE':
                hidden_collection.hide_viewport = True
                hidden_collection.hide_render = True
                self.report({'INFO'}, "éšè—å¯¼å…¥é›†åˆå·²éšè—")
                
            elif self.action == 'CLEAR':
                # æ¸…ç©ºé›†åˆä¸­çš„æ‰€æœ‰ç‰©ä½“
                objects_to_remove = list(hidden_collection.objects)
                removed_count = 0
                
                for obj in objects_to_remove:
                    try:
                        bpy.data.objects.remove(obj, do_unlink=True)
                        removed_count += 1
                    except Exception as e:
                        print(f"åˆ é™¤ç‰©ä½“ '{obj.name}' æ—¶å‡ºé”™: {e}")
                
                self.report({'INFO'}, f"å·²æ¸…ç©ºéšè—é›†åˆï¼Œåˆ é™¤äº† {removed_count} ä¸ªç‰©ä½“")
                
            elif self.action == 'INFO':
                object_count = len(hidden_collection.objects)
                self.report({'INFO'}, f"éšè—é›†åˆåŒ…å« {object_count} ä¸ªç‰©ä½“")
                
                # æ‰“å°è¯¦ç»†ä¿¡æ¯
                print(f"éšè—å¯¼å…¥é›†åˆä¿¡æ¯:")
                print(f"  é›†åˆåç§°: {hidden_collection.name}")
                print(f"  ç‰©ä½“æ•°é‡: {object_count}")
                print(f"  è§†å£å¯è§: {not hidden_collection.hide_viewport}")
                print(f"  æ¸²æŸ“å¯è§: {not hidden_collection.hide_render}")
                
                if object_count > 0:
                    print(f"  ç‰©ä½“åˆ—è¡¨:")
                    for obj in hidden_collection.objects:
                        print(f"    - {obj.name} ({obj.type})")
            
            return {'FINISHED'}
            
        except Exception as e:
            self.report({'ERROR'}, f"ç®¡ç†éšè—é›†åˆæ—¶å‡ºç°é”™è¯¯: {str(e)}")
            return {'CANCELLED'}


def smart_body_part_replacement(source_obj, source_parsed, target_objects):
    """æ™ºèƒ½èº«ä½“éƒ¨ä»¶æ›¿æ¢é€»è¾‘
    
    ä¼˜å…ˆçº§ï¼šä¸Šèº« > ä¸‹èº« > å¤´å‘
    ç­–ç•¥ï¼š
    1. å¦‚æœæ˜¯å¤´å‘æˆ–ä¸‹èº«ï¼Œä¼˜å…ˆå‚è€ƒä¸Šèº«æ˜¯å¦ä¸ºå¥—è£…
    2. å¦‚æœä¸Šèº«ä¸æ˜¯å¥—è£…ï¼Œåˆ™çœ‹ä¸‹èº«æ˜¯å¦ä¸ºå¥—è£…
    3. å¦‚æœä¸‹èº«ä¸æ˜¯å¥—è£…ï¼Œåˆ™çœ‹å¤´å‘æ˜¯å¦ä¸ºå¥—è£…
    4. å¦‚æœéƒ½ä¸æ˜¯å¥—è£…ï¼Œåˆ™éšæœºé€‰å–åŒç±»éƒ¨ä»¶
    5. å¦‚æœéƒ½æ˜¯å¥—è£…ï¼Œåˆ™å‚è€ƒä¸Šèº«è¿›è¡Œæ›¿æ¢
    6. å¦‚æœä¸æ˜¯è¿™ä¸‰ç§éƒ¨ä»¶ç±»å‹ï¼Œåˆ™éšæœºæ›¿æ¢åŒç±»éƒ¨ä»¶
    
    Args:
        source_obj: æºç‰©ä½“
        source_parsed: æºç‰©ä½“è§£æä¿¡æ¯
        target_objects: ç›®æ ‡ç‰©ä½“åˆ—è¡¨
        
    Returns:
        dict or None: åŒ¹é…çš„ç›®æ ‡ç‰©ä½“
    """
    print(f"ğŸ§  æ™ºèƒ½èº«ä½“éƒ¨ä»¶æ›¿æ¢:")
    print(f"   æºéƒ¨ä»¶: {source_obj.name} (éƒ¨ä½: {source_parsed['parts']})")
    
    # è·å–æ‰€æœ‰èº«ä½“éƒ¨ä»¶
    body_parts = get_all_body_parts(source_obj, source_parsed['gender'])
    
    if not body_parts:
        print(f"   âŒ æœªæ‰¾åˆ°ä»»ä½•èº«ä½“éƒ¨ä»¶ï¼Œéšæœºæ›¿æ¢åŒç±»éƒ¨ä»¶")
        return find_matching_random_target(source_parsed['gender'], source_parsed['parts'], target_objects)
    
    print(f"   ğŸ“‹ æ‰¾åˆ°èº«ä½“éƒ¨ä»¶:")
    for part_type, part_obj in body_parts.items():
        part_parsed = parse_object_name(part_obj.name)
        print(f"      {part_type}: {part_obj.name} (å¥—è£…: {part_parsed['is_set']})")
    
    # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥å¥—è£…çŠ¶æ€
    priority_order = ['upper', 'lower', 'hair']
    set_parts = []
    
    for part_type in priority_order:
        if part_type in body_parts:
            part_obj = body_parts[part_type]
            part_parsed = parse_object_name(part_obj.name)
            if part_parsed['is_set']:
                set_parts.append((part_type, part_obj, part_parsed))
                print(f"   âœ… {part_type} æ˜¯å¥—è£…")
            else:
                print(f"   âŒ {part_type} ä¸æ˜¯å¥—è£…")
    
    # å†³å®šæ›¿æ¢ç­–ç•¥
    if set_parts:
        # æœ‰å¥—è£…éƒ¨ä»¶ï¼Œä¼˜å…ˆä½¿ç”¨ä¸Šèº«å¥—è£…
        if any(part_type == 'upper' for part_type, _, _ in set_parts):
            reference_part_type = 'upper'
        else:
            # ä¸Šèº«ä¸æ˜¯å¥—è£…ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¥—è£…
            reference_part_type = set_parts[0][0]
        
        reference_obj = body_parts[reference_part_type]
        reference_parsed = parse_object_name(reference_obj.name)
        
        print(f"   ğŸ¯ é€‰æ‹©å‚è€ƒå¥—è£…: {reference_part_type} ({reference_obj.name})")
        
        # æŸ¥æ‰¾åŒ¹é…çš„ç›®æ ‡å¥—è£…
        target_set_obj = find_matching_target_set(reference_parsed, target_objects)
        
        if target_set_obj:
            print(f"   âœ… æ‰¾åˆ°åŒ¹é…çš„ç›®æ ‡å¥—è£…")
            
            # åœ¨ç›®æ ‡å¥—è£…ä¸­æŸ¥æ‰¾åŒ¹é…çš„éƒ¨ä»¶
            target_obj = find_matching_part_in_set(source_obj, target_set_obj, target_objects)
            
            if target_obj:
                print(f"   ğŸ¯ å¥—è£…æ›¿æ¢æˆåŠŸ")
                return target_obj
            else:
                print(f"   âš ï¸ ç›®æ ‡å¥—è£…ä¸­æ— åŒ¹é…éƒ¨ä»¶ï¼Œéšæœºæ›¿æ¢åŒç±»éƒ¨ä»¶")
                return find_matching_random_target(source_parsed['gender'], source_parsed['parts'], target_objects)
        else:
            print(f"   âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„ç›®æ ‡å¥—è£…ï¼Œéšæœºæ›¿æ¢åŒç±»éƒ¨ä»¶")
            return find_matching_random_target(source_parsed['gender'], source_parsed['parts'], target_objects)
    else:
        print(f"   âš ï¸ æ‰€æœ‰èº«ä½“éƒ¨ä»¶éƒ½ä¸æ˜¯å¥—è£…ï¼Œéšæœºæ›¿æ¢åŒç±»éƒ¨ä»¶")
        return find_matching_random_target(source_parsed['gender'], source_parsed['parts'], target_objects)

def get_all_body_parts(source_obj, gender):
    """è·å–æ‰€æœ‰èº«ä½“éƒ¨ä»¶ï¼ˆä¸Šèº«ã€ä¸‹èº«ã€å¤´å‘ï¼‰
    
    Args:
        source_obj: æºç‰©ä½“
        gender: æ€§åˆ«
        
    Returns:
        dict: {part_type: part_obj} èº«ä½“éƒ¨ä»¶å­—å…¸
    """
    # è·å–é¡¶çº§çˆ¶çº§
    top_parent = source_obj
    while top_parent.parent:
        top_parent = top_parent.parent
    
    # éå†é¡¶çº§çˆ¶çº§ä¸‹çš„æ‰€æœ‰å­ç‰©ä½“
    def get_all_children(obj):
        children = []
        for child in obj.children:
            children.append(child)
            children.extend(get_all_children(child))
        return children
    
    all_children = get_all_children(top_parent)
    
    # æŸ¥æ‰¾èº«ä½“éƒ¨ä»¶
    body_parts = {}
    body_part_types = ['upper', 'lower', 'hair']
    
    for child in all_children:
        if child.type != 'MESH':
            continue
            
        child_parsed = parse_object_name(child.name)
        
        # æ£€æŸ¥æ€§åˆ«å’Œéƒ¨ä½æ˜¯å¦åŒ¹é…
        if (child_parsed['gender'] == gender and 
            any(part in child_parsed['parts'] for part in body_part_types)):
            
            for part_type in body_part_types:
                if part_type in child_parsed['parts']:
                    body_parts[part_type] = child
                    break
    
    return body_parts

def smart_multi_selection_replacement(source_objects, target_objects):
    """æ™ºèƒ½å¤šé€‰æ›¿æ¢é€»è¾‘
    
    ç­–ç•¥ï¼šè‡ªåŠ¨æ£€æµ‹æ‰€æœ‰é¡¶çº§çˆ¶çº§ï¼ŒæŒ‰é¡¶çº§çˆ¶çº§åˆ†ç»„ç‰©ä½“ï¼Œ
    å¦‚æœå‹¾é€‰å¥—è£…æ›¿æ¢åˆ™å¯¹æ¯ç»„çš„ç‰©ä½“è¿›è¡Œä¸€å¥—å†…å¥—è£…çš„æ›¿æ¢
    
    Args:
        source_objects: æºç‰©ä½“åˆ—è¡¨
        target_objects: ç›®æ ‡ç‰©ä½“åˆ—è¡¨
        
    Returns:
        list: æ›¿æ¢è®¡åˆ’ [(source_obj, target_obj), ...]
    """
    print(f"ğŸ§  æ™ºèƒ½å¤šé€‰æ›¿æ¢:")
    print(f"   æºç‰©ä½“æ•°é‡: {len(source_objects)}")
    print(f"   ç›®æ ‡ç‰©ä½“æ•°é‡: {len(target_objects)}")
    
    replacement_plan = []
    used_target_objects = set()  # è·Ÿè¸ªå·²ä½¿ç”¨çš„ç›®æ ‡ç‰©ä½“
    
    # æŒ‰é¡¶çº§çˆ¶çº§åˆ†ç»„æºç‰©ä½“
    source_groups_by_parent = group_objects_by_parent(source_objects)
    
    print(f"\nğŸ“¦ è‡ªåŠ¨æ£€æµ‹é¡¶çº§çˆ¶çº§åˆ†ç»„:")
    for parent_name, parent_objects in source_groups_by_parent.items():
        print(f"   çˆ¶çº§: {parent_name}")
        print(f"     ç‰©ä½“æ•°é‡: {len(parent_objects)}")
        for obj in parent_objects:
            parsed = parse_object_name(obj.name)
            print(f"       - {obj.name} (æ€§åˆ«: {parsed['gender']}, éƒ¨ä½: {parsed['parts']})")
    
    # ä¸ºæ¯ä¸ªçˆ¶çº§ç»„ç‹¬ç«‹æ‰§è¡Œå¥—è£…æ›¿æ¢
    for group_index, (parent_name, parent_objects) in enumerate(source_groups_by_parent.items()):
        print(f"\nğŸ¯ å¤„ç†çˆ¶çº§ç»„ {group_index + 1}/{len(source_groups_by_parent)}: {parent_name}")
        
        # ä¸ºå½“å‰çˆ¶çº§ç»„æ‰§è¡Œå¥—è£…æ›¿æ¢
        group_replacement_plan = execute_parent_group_set_replacement(
            parent_objects, target_objects, used_target_objects
        )
        
        # æ·»åŠ åˆ°æ€»æ›¿æ¢è®¡åˆ’
        replacement_plan.extend(group_replacement_plan)
        
        print(f"   ğŸ“‹ çˆ¶çº§ç»„æ›¿æ¢ç»“æœ: {len(group_replacement_plan)} ä¸ªæ›¿æ¢")
        for source_obj, target_obj in group_replacement_plan:
            print(f"      {source_obj.name} -> {target_obj['name']}")
    
    print(f"\nâœ… æ™ºèƒ½å¤šé€‰æ›¿æ¢å®Œæˆ: å…± {len(replacement_plan)} ä¸ªæ›¿æ¢")
    return replacement_plan

def execute_parent_group_set_replacement(parent_objects, target_objects, used_target_objects):
    """ä¸ºå•ä¸ªçˆ¶çº§ç»„æ‰§è¡Œå¥—è£…æ›¿æ¢
    
    Args:
        parent_objects: çˆ¶çº§ç»„ä¸­çš„ç‰©ä½“åˆ—è¡¨
        target_objects: æ‰€æœ‰ç›®æ ‡ç‰©ä½“åˆ—è¡¨
        used_target_objects: å·²ä½¿ç”¨çš„ç›®æ ‡ç‰©ä½“é›†åˆ
        
    Returns:
        list: æ›¿æ¢è®¡åˆ’ [(source_obj, target_obj), ...]
    """
    replacement_plan = []
    
    # æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾å‚è€ƒéƒ¨ä»¶ï¼šä¸Šèº« > ä¸‹èº« > å¤´å‘
    reference_obj = find_reference_body_part_by_priority(parent_objects)
    
    if reference_obj:
        reference_parsed = parse_object_name(reference_obj.name)
        print(f"   âœ… æ‰¾åˆ°å‚è€ƒéƒ¨ä»¶: {reference_obj.name}")
        print(f"      æ€§åˆ«: {reference_parsed['gender']}, éƒ¨ä½: {reference_parsed['parts']}")
        
        # æ£€æŸ¥å‚è€ƒéƒ¨ä»¶æ˜¯å¦ä¸ºå¥—è£…
        if reference_parsed['is_set']:
            print(f"   ğŸ¯ å‚è€ƒéƒ¨ä»¶æ˜¯å¥—è£…ï¼ŒæŒ‰å¥—è£…æ›¿æ¢")
            
            # æŸ¥æ‰¾åŒ¹é…çš„ç›®æ ‡å¥—è£…ï¼ˆæ’é™¤å·²ä½¿ç”¨çš„ï¼‰
            target_set_obj = find_matching_target_set_excluding_used(
                reference_parsed, target_objects, used_target_objects
            )
            
            if target_set_obj:
                print(f"   âœ… æ‰¾åˆ°åŒ¹é…çš„ç›®æ ‡å¥—è£…")
                
                # è·å–ç›®æ ‡å¥—è£…ä¸­çš„æ‰€æœ‰ç‰©ä½“
                target_set_objects = get_target_set_objects(target_set_obj, target_objects)
                
                # ä¸ºçˆ¶çº§ç»„ä¸­çš„æ¯ä¸ªç‰©ä½“åœ¨ç›®æ ‡å¥—è£…ä¸­æŸ¥æ‰¾åŒ¹é…çš„éƒ¨ä»¶
                for source_obj in parent_objects:
                    target_obj = find_matching_part_in_target_set(
                        source_obj, target_set_objects, used_target_objects
                    )
                    
                    if target_obj:
                        replacement_plan.append((source_obj, target_obj))
                        used_target_objects.add(target_obj['name'])
                        print(f"     âœ… å¥—è£…æ›¿æ¢: {source_obj.name} -> {target_obj['name']}")
                    else:
                        # ç›®æ ‡å¥—è£…ä¸­æ— åŒ¹é…éƒ¨ä»¶ï¼ŒæŸ¥æ‰¾æ€§åˆ«å’Œéƒ¨ä»¶åŒ¹é…çš„éšæœºæ›¿æ¢
                        target_obj = find_matching_random_target_excluding_used(
                            reference_parsed['gender'], 
                            parse_object_name(source_obj.name)['parts'], 
                            target_objects,
                            used_target_objects
                        )
                        if target_obj:
                            replacement_plan.append((source_obj, target_obj))
                            used_target_objects.add(target_obj['name'])
                            print(f"     ğŸ¯ ç²¾ç¡®åŒ¹é…éšæœºæ›¿æ¢: {source_obj.name} -> {target_obj['name']}")
                        else:
                            print(f"     â­ï¸ è·³è¿‡ {source_obj.name}ï¼šæ— æ€§åˆ«å’Œéƒ¨ä»¶åŒ¹é…çš„ç›®æ ‡")
            else:
                print(f"   âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„ç›®æ ‡å¥—è£…ï¼Œæ‰§è¡Œéšæœºæ›¿æ¢")
                # ä¸ºçˆ¶çº§ç»„ä¸­çš„æ¯ä¸ªç‰©ä½“æ‰§è¡Œéšæœºæ›¿æ¢
                for source_obj in parent_objects:
                    target_obj = find_matching_random_target_excluding_used(
                        reference_parsed['gender'], 
                        parse_object_name(source_obj.name)['parts'], 
                        target_objects,
                        used_target_objects
                    )
                    if target_obj:
                        replacement_plan.append((source_obj, target_obj))
                        used_target_objects.add(target_obj['name'])
                        print(f"     ğŸ¯ éšæœºæ›¿æ¢: {source_obj.name} -> {target_obj['name']}")
                    else:
                        print(f"     â­ï¸ è·³è¿‡: {source_obj.name}")
        else:
            print(f"   âš ï¸ å‚è€ƒéƒ¨ä»¶ä¸æ˜¯å¥—è£…ï¼Œæ‰§è¡Œéšæœºæ›¿æ¢")
            # ä¸ºçˆ¶çº§ç»„ä¸­çš„æ¯ä¸ªç‰©ä½“æ‰§è¡Œéšæœºæ›¿æ¢
            for source_obj in parent_objects:
                target_obj = find_matching_random_target_excluding_used(
                    reference_parsed['gender'], 
                    parse_object_name(source_obj.name)['parts'], 
                    target_objects,
                    used_target_objects
                )
                if target_obj:
                    replacement_plan.append((source_obj, target_obj))
                    used_target_objects.add(target_obj['name'])
                    print(f"     ğŸ¯ éšæœºæ›¿æ¢: {source_obj.name} -> {target_obj['name']}")
                else:
                    print(f"     â­ï¸ è·³è¿‡: {source_obj.name}")
    else:
        print(f"   âŒ æœªæ‰¾åˆ°å‚è€ƒéƒ¨ä»¶ï¼Œæ‰§è¡Œéšæœºæ›¿æ¢")
        # ä¸ºçˆ¶çº§ç»„ä¸­çš„æ¯ä¸ªç‰©ä½“æ‰§è¡Œéšæœºæ›¿æ¢
        for source_obj in parent_objects:
            source_parsed = parse_object_name(source_obj.name)
            target_obj = find_matching_random_target_excluding_used(
                source_parsed['gender'], 
                source_parsed['parts'], 
                target_objects,
                used_target_objects
            )
            if target_obj:
                replacement_plan.append((source_obj, target_obj))
                used_target_objects.add(target_obj['name'])
                print(f"     ğŸ¯ éšæœºæ›¿æ¢: {source_obj.name} -> {target_obj['name']}")
            else:
                print(f"     â­ï¸ è·³è¿‡: {source_obj.name}")
    
    return replacement_plan

def find_matching_target_set_excluding_used(reference_parsed, target_objects, used_target_objects):
    """æŸ¥æ‰¾åŒ¹é…çš„ç›®æ ‡å¥—è£…ï¼ˆæ’é™¤å·²ä½¿ç”¨çš„ï¼‰
    
    Args:
        reference_parsed: å‚è€ƒéƒ¨ä»¶è§£æä¿¡æ¯
        target_objects: ç›®æ ‡ç‰©ä½“åˆ—è¡¨
        used_target_objects: å·²ä½¿ç”¨çš„ç›®æ ‡ç‰©ä½“é›†åˆ
        
    Returns:
        dict or None: åŒ¹é…çš„ç›®æ ‡å¥—è£…ä¿¡æ¯
    """
    # æŒ‰å¥—è£…åˆ†ç»„ç›®æ ‡ç‰©ä½“
    target_sets = group_objects_by_sets_smart([{'name': obj['name'], 'parsed_info': obj['parsed_info']} for obj in target_objects])
    
    # æŸ¥æ‰¾åŒ¹é…çš„å¥—è£…
    matching_sets = []
    for set_id, set_info in target_sets.items():
        # æ£€æŸ¥æ€§åˆ«æ˜¯å¦åŒ¹é…
        if set_info['gender'] != reference_parsed['gender']:
            continue
        
        # æ£€æŸ¥å¥—è£…ä¸­æ˜¯å¦æœ‰æœªä½¿ç”¨çš„ç‰©ä½“
        has_unused_objects = False
        for obj_info in set_info['objects']:
            if obj_info['name'] not in used_target_objects:
                has_unused_objects = True
                break
        
        if has_unused_objects:
            matching_sets.append((set_id, set_info))
    
    if matching_sets:
        # éšæœºé€‰æ‹©ä¸€ä¸ªåŒ¹é…çš„å¥—è£…
        set_id, set_info = random.choice(matching_sets)
        return {'set_id': set_id, 'set_info': set_info}
    
    return None

def get_target_set_objects(target_set_obj, target_objects):
    """è·å–ç›®æ ‡å¥—è£…ä¸­çš„æ‰€æœ‰ç‰©ä½“
    
    Args:
        target_set_obj: ç›®æ ‡å¥—è£…ä¿¡æ¯
        target_objects: æ‰€æœ‰ç›®æ ‡ç‰©ä½“åˆ—è¡¨
        
    Returns:
        list: ç›®æ ‡å¥—è£…ä¸­çš„ç‰©ä½“åˆ—è¡¨
    """
    set_objects = []
    set_info = target_set_obj['set_info']
    
    for obj_info in set_info['objects']:
        # åœ¨ç›®æ ‡ç‰©ä½“åˆ—è¡¨ä¸­æŸ¥æ‰¾å¯¹åº”çš„ç‰©ä½“
        for target_obj in target_objects:
            if target_obj['name'] == obj_info['name']:
                set_objects.append(target_obj)
                break
    
    return set_objects

def find_matching_part_in_target_set(source_obj, target_set_objects, used_target_objects):
    """åœ¨ç›®æ ‡å¥—è£…ä¸­æŸ¥æ‰¾åŒ¹é…çš„éƒ¨ä»¶ï¼ˆæ’é™¤å·²ä½¿ç”¨çš„ï¼‰
    
    Args:
        source_obj: æºç‰©ä½“
        target_set_objects: ç›®æ ‡å¥—è£…ä¸­çš„ç‰©ä½“åˆ—è¡¨
        used_target_objects: å·²ä½¿ç”¨çš„ç›®æ ‡ç‰©ä½“é›†åˆ
        
    Returns:
        dict or None: åŒ¹é…çš„ç›®æ ‡ç‰©ä½“
    """
    source_parsed = parse_object_name(source_obj.name)
    
    # ä¸¥æ ¼åŒ¹é…ï¼šåªè¿”å›éƒ¨ä»¶ç±»å‹å®Œå…¨ç›¸åŒçš„ç‰©ä½“
    for target_obj in target_set_objects:
        if target_obj['name'] in used_target_objects:
            continue
            
        target_parsed = parse_object_name(target_obj['name'])
        
        # æ£€æŸ¥æ€§åˆ«å’Œéƒ¨ä»¶æ˜¯å¦ä¸¥æ ¼åŒ¹é…
        if (target_parsed['gender'] == source_parsed['gender'] and 
            is_exact_part_match(source_parsed['parts'], target_parsed['parts'])):
            return target_obj
    
    # å¦‚æœæ²¡æœ‰ä¸¥æ ¼åŒ¹é…ï¼Œè¿”å›Noneï¼ˆä¸è¿›è¡Œå›é€€ï¼‰
    return None

def find_matching_random_target_excluding_used(gender, parts, target_objects, used_target_objects):
    """æŸ¥æ‰¾åŒ¹é…çš„éšæœºç›®æ ‡ï¼ˆæ’é™¤å·²ä½¿ç”¨çš„ï¼‰
    
    Args:
        gender: æ€§åˆ«
        parts: éƒ¨ä»¶åˆ—è¡¨
        target_objects: ç›®æ ‡ç‰©ä½“åˆ—è¡¨
        used_target_objects: å·²ä½¿ç”¨çš„ç›®æ ‡ç‰©ä½“é›†åˆ
        
    Returns:
        dict or None: åŒ¹é…çš„ç›®æ ‡ç‰©ä½“
    """
    matching_targets = []
    
    for target_obj in target_objects:
        if target_obj['name'] in used_target_objects:
            continue
            
        target_parsed = parse_object_name(target_obj['name'])
        
        if (target_parsed['gender'] == gender and 
            is_exact_part_match(parts, target_parsed['parts'])):
            matching_targets.append(target_obj)
    
    if matching_targets:
        return random.choice(matching_targets)
    
    return None

def register():
    bpy.utils.register_class(mian_OT_ObjectClassifier)
    bpy.utils.register_class(mian_OT_ObjectReplacer)
    bpy.utils.register_class(mian_OT_ManageHiddenCollection)

def group_objects_by_parent(objects):
    """æŒ‰é¡¶çº§çˆ¶çº§åˆ†ç»„ç‰©ä½“
    
    Args:
        objects: ç‰©ä½“åˆ—è¡¨
        
    Returns:
        dict: {parent_name: [objects]} æŒ‰çˆ¶çº§åˆ†ç»„çš„ç‰©ä½“å­—å…¸
    """
    groups = {}
    
    for obj in objects:
        # è·å–é¡¶çº§çˆ¶çº§
        top_parent = obj
        while top_parent.parent:
            top_parent = top_parent.parent
        
        parent_name = top_parent.name
        
        if parent_name not in groups:
            groups[parent_name] = []
        
        groups[parent_name].append(obj)
    
    return groups

def find_reference_body_part_by_priority(objects):
    """æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾å‚è€ƒéƒ¨ä»¶ï¼šä¸Šèº« > ä¸‹èº« > å¤´å‘
    
    Args:
        objects: ç‰©ä½“åˆ—è¡¨
        
    Returns:
        bpy.types.Object or None: æ‰¾åˆ°çš„å‚è€ƒéƒ¨ä»¶
    """
    print(f"ğŸ” æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾å‚è€ƒéƒ¨ä»¶: ä¸Šèº« > ä¸‹èº« > å¤´å‘")
    
    # ä¼˜å…ˆçº§é¡ºåº
    priority_parts = ['upper', 'lower', 'hair']
    
    for priority_part in priority_parts:
        for obj in objects:
            if obj.type != 'MESH':
                continue
                
            parsed = parse_object_name(obj.name)
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å½“å‰ä¼˜å…ˆçº§éƒ¨ä½
            if priority_part in parsed['parts']:
                print(f"   âœ… æ‰¾åˆ°å‚è€ƒéƒ¨ä»¶: {obj.name} (éƒ¨ä½: {priority_part})")
                return obj
    
    print(f"   âŒ æœªæ‰¾åˆ°ä»»ä½•èº«ä½“éƒ¨ä»¶")
    return None

def register():
    bpy.utils.register_class(mian_OT_ObjectClassifier)
    bpy.utils.register_class(mian_OT_ObjectReplacer)
    bpy.utils.register_class(mian_OT_ManageHiddenCollection)

def unregister():
    bpy.utils.unregister_class(mian_OT_ObjectClassifier)
    bpy.utils.unregister_class(mian_OT_ObjectReplacer)
    bpy.utils.unregister_class(mian_OT_ManageHiddenCollection)